{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ngram_laplace_lm_model as lm\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "NGRAM = 3\n",
    "VERBOSE = True\n",
    "SENTENCE_BEGIN = \"<s>\"\n",
    "SENTENCE_END = \"</s>\"\n",
    "NEWLINE = \" NEW \"\n",
    "\n",
    "GENRE = \"Heavy Metal\"\n",
    "SONG_LIMIT = None\n",
    "\n",
    "# define a percentage of the data to use for training\n",
    "SPLIT_PC = .80\n",
    "\n",
    "# True to train by groups of lines, False to train by single lines \n",
    "BY_VERSE = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163020, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                          song_name  \\\n",
       "0  ivete sangalo                                   Careless Whisper   \n",
       "1  ivete sangalo  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "2  ivete sangalo                             Cruisin' (Part. Saulo)   \n",
       "3  ivete sangalo                                               Easy   \n",
       "4  ivete sangalo                  For Your Babies (The Voice cover)   \n",
       "\n",
       "                                              lyrics language  \\\n",
       "0  I feel so unsure\\nAs I take your hand and lead...       en   \n",
       "1  Don't let them fool, ya\\nOr even try to school...       en   \n",
       "2  Baby, let's cruise, away from here\\nDon't be c...       en   \n",
       "3  Know it sounds funny\\nBut, I just can't stand ...       en   \n",
       "4  You've got that look again\\nThe one I hoped I ...       en   \n",
       "\n",
       "                          genres  \n",
       "0  ['Pop', ' Axé', ' Romântico']  \n",
       "1  ['Pop', ' Axé', ' Romântico']  \n",
       "2  ['Pop', ' Axé', ' Romântico']  \n",
       "3  ['Pop', ' Axé', ' Romântico']  \n",
       "4  ['Pop', ' Axé', ' Romântico']  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in cleaned data\n",
    "song_df = pd.read_csv('clean_data.csv')\n",
    "print(song_df.shape)\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 18849 / 18849 in the genre Heavy Metal\n",
      "Total sequences: 142294\n",
      "Number of lines in training data: 113835\n",
      "Number of lines in test data: 28459\n",
      "Lyric example: become one with imagination NEW no more fairytales (no more fairytales) NEW our souls will unite together NEW we will lift the veil (lift the veil)\n"
     ]
    }
   ],
   "source": [
    "# get song lyrics of the given genre \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "song_lyrics = utils.get_lyrics_in_genre(song_df, GENRE, verbose=VERBOSE, by_verse=BY_VERSE, song_limit=SONG_LIMIT)\n",
    "\n",
    "# calculate the last index for the training data\n",
    "END = int(len(song_lyrics) * SPLIT_PC) \n",
    "\n",
    "# separate train and test data\n",
    "train_lyrics = song_lyrics[0:END]\n",
    "test_lyrics = song_lyrics[END:]\n",
    "\n",
    "# check dimensions\n",
    "print(\"Number of lines in training data:\", len(train_lyrics))\n",
    "print(\"Number of lines in test data:\", len(test_lyrics))\n",
    "\n",
    "print(\"Lyric example:\", train_lyrics[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to help format generated sentences \n",
    "def clean_lyric(lyric_tokens: list) -> str:\n",
    "    \"\"\"\n",
    "    Return the given sequence of tokens as a single string without special tokens like <s> or </s>\n",
    "\n",
    "    Args:\n",
    "        lyric_tokens (list): list of tokens for the generated sequence\n",
    "\n",
    "    Returns:\n",
    "        The tokens joined in a single string without special characters \n",
    "\n",
    "    \"\"\"\n",
    "    lyric_str = ' '.join(lyric_tokens)\n",
    "    lyric_str = lyric_str.replace(NEWLINE, '\\n')\n",
    "    return lyric_str.replace(SENTENCE_BEGIN, '').replace(SENTENCE_END, '').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using NLTK Model with Kneser-Ney Smoothing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_kneser_ney_model(sequences: list, ngram: int = NGRAM, verbose: bool = True):\n",
    "\t\"\"\"\n",
    "\t Creates a trained n-gram language model using Kneser-Ney Smoothing. Model will be trained on songs in the given \n",
    "\t music genre. \n",
    "\n",
    "\t Args:\n",
    "\t\tsequences (list): a list of training sequence strings, not tokenized \n",
    "\t\tngram (int): the n-gram order of the language model to create\n",
    "\t\tverbose (bool): if True, prints information about the training data \n",
    "\t\t\t\t\n",
    "\tReturns:\n",
    "\t\tA trained KneserNeyInterpolated\n",
    "\t\"\"\"\n",
    "\t# split each line into tokens \n",
    "\ttokens = [utils.tokenize_line(seq, ngram) for seq in sequences]\n",
    "\n",
    "\t# allow padded_everygram_pipeline to create ngrams for the model \n",
    "\tngrams_generator, padded_sents = padded_everygram_pipeline(ngram, tokens)\n",
    "\n",
    "\tmodel = nltk.lm.Laplace(ngram)\n",
    "\tmodel.fit(ngrams_generator, padded_sents)\n",
    "     \n",
    "\tif verbose:\n",
    "\t\tprint(\"Number of tokens:\", len(tokens))\n",
    "\t\tprint(\"Vocabulary Size:\", len(model.vocab))\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 1344\n",
      "Vocabulary Size: 1172\n"
     ]
    }
   ],
   "source": [
    "kneser_ney_model = create_ngram_kneser_ney_model(train_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Generated Lyrics: Pop \n",
      "\n",
      "i got pounds , jungkook ]\n",
      "you should crown me\n",
      "[ chorus\n",
      "we 're on and the phony innocence\n",
      "and pleasure is a long time to act , i need your head my girl\n",
      "i want to relay\n",
      "so high flyer\n",
      "liberation\n",
      "education\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\ngram.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSample Generated Lyrics:\u001b[39m\u001b[39m\"\u001b[39m, GENRE, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_SEQ):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     lyric_tokens \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(kneser_ney_model\u001b[39m.\u001b[39;49mgenerate(max_len, seed))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(clean_lyric(lyric_tokens))\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\api.py:229\u001b[0m, in \u001b[0;36mLanguageModel.generate\u001b[1;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[0;32m    226\u001b[0m generated \u001b[39m=\u001b[39m []\n\u001b[0;32m    227\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_words):\n\u001b[0;32m    228\u001b[0m     generated\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 229\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[0;32m    230\u001b[0m             num_words\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    231\u001b[0m             text_seed\u001b[39m=\u001b[39;49mtext_seed \u001b[39m+\u001b[39;49m generated,\n\u001b[0;32m    232\u001b[0m             random_seed\u001b[39m=\u001b[39;49mrandom_generator,\n\u001b[0;32m    233\u001b[0m         )\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m generated\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\api.py:222\u001b[0m, in \u001b[0;36mLanguageModel.generate\u001b[1;34m(self, num_words, text_seed, random_seed)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# Sorting samples achieves two things:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# - reproducible randomness when sampling\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# - turns Mapping into Sequence which `_weighted_choice` expects\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(samples)\n\u001b[0;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m _weighted_choice(\n\u001b[0;32m    221\u001b[0m         samples,\n\u001b[1;32m--> 222\u001b[0m         \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore(w, context) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m samples),\n\u001b[0;32m    223\u001b[0m         random_generator,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[0;32m    225\u001b[0m \u001b[39m# We build up text one word at a time using the preceding context.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m generated \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\api.py:222\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# Sorting samples achieves two things:\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# - reproducible randomness when sampling\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# - turns Mapping into Sequence which `_weighted_choice` expects\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(samples)\n\u001b[0;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m _weighted_choice(\n\u001b[0;32m    221\u001b[0m         samples,\n\u001b[1;32m--> 222\u001b[0m         \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore(w, context) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m samples),\n\u001b[0;32m    223\u001b[0m         random_generator,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[0;32m    225\u001b[0m \u001b[39m# We build up text one word at a time using the preceding context.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m generated \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\api.py:124\u001b[0m, in \u001b[0;36mLanguageModel.score\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, word, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    119\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Masks out of vocab (OOV) words and computes their model score.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[39m    For model-specific logic of calculating scores, see the `unmasked_score`\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39m    method.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munmasked_score(\n\u001b[0;32m    125\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mlookup(word), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mlookup(context) \u001b[39mif\u001b[39;49;00m context \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    126\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\models.py:112\u001b[0m, in \u001b[0;36mInterpolatedLanguageModel.unmasked_score\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m     alpha, gamma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39malpha_gamma(word, context)\n\u001b[1;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m alpha \u001b[39m+\u001b[39m gamma \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munmasked_score(word, context[\u001b[39m1\u001b[39;49m:])\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\models.py:104\u001b[0m, in \u001b[0;36mInterpolatedLanguageModel.unmasked_score\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munmasked_score\u001b[39m(\u001b[39mself\u001b[39m, word, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context:\n\u001b[0;32m    103\u001b[0m         \u001b[39m# The base recursion case: no context, we only have a unigram.\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49munigram_score(word)\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounts[context]:\n\u001b[0;32m    106\u001b[0m         \u001b[39m# It can also happen that we have no data for this context.\u001b[39;00m\n\u001b[0;32m    107\u001b[0m         \u001b[39m# In that case we defer to the lower-order ngram.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m         \u001b[39m# This is the same as setting alpha to 0 and gamma to 1.\u001b[39;00m\n\u001b[0;32m    109\u001b[0m         alpha, gamma \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\smoothing.py:97\u001b[0m, in \u001b[0;36mKneserNey.unigram_score\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munigram_score\u001b[39m(\u001b[39mself\u001b[39m, word):\n\u001b[1;32m---> 97\u001b[0m     word_continuation_count, total_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_continuation_counts(word)\n\u001b[0;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m word_continuation_count \u001b[39m/\u001b[39m total_count\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\nltk\\lm\\smoothing.py:125\u001b[0m, in \u001b[0;36mKneserNey._continuation_counts\u001b[1;34m(self, word, context)\u001b[0m\n\u001b[0;32m    123\u001b[0m higher_order_ngrams_with_word_count, total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[0;32m    124\u001b[0m \u001b[39mfor\u001b[39;00m counts \u001b[39min\u001b[39;00m higher_order_ngrams_with_context:\n\u001b[1;32m--> 125\u001b[0m     higher_order_ngrams_with_word_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(counts[word] \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    126\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _count_values_gt_zero(counts)\n\u001b[0;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m higher_order_ngrams_with_word_count, total\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate 10 lines and print them out \n",
    "NUM_SEQ = 15 \n",
    "seed = [SENTENCE_BEGIN] * (NGRAM - 1)\n",
    "max_len = 15 # nltk's models generate sequences of a fixed length \n",
    "\n",
    "print(\"Sample Generated Lyrics:\", GENRE, \"\\n\")\n",
    "for i in range(NUM_SEQ):\n",
    "    lyric_tokens = list(kneser_ney_model.generate(max_len, seed))\n",
    "    print(clean_lyric(lyric_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'man', 'condemned', 'again', 'NEW', 'fallen', 'at', 'the', 'image', 'NEW', 'man', 'condemned', 'again', 'of', 'pain', 'NEW', 'i', 'am', 'the', 'son', 'of', 'the', 'earth', 'NEW', 'pain', '!', '</s>']\n",
      "[('<s>', 'man'), ('man', 'condemned'), ('condemned', 'again'), ('again', 'NEW'), ('NEW', 'fallen'), ('fallen', 'at'), ('at', 'the'), ('the', 'image'), ('image', 'NEW'), ('NEW', 'man'), ('man', 'condemned'), ('condemned', 'again'), ('again', 'of'), ('of', 'pain'), ('pain', 'NEW'), ('NEW', 'i'), ('i', 'am'), ('am', 'the'), ('the', 'son'), ('son', 'of'), ('of', 'the'), ('the', 'earth'), ('earth', 'NEW'), ('NEW', 'pain!'), ('pain!', '</s>')]\n",
      "[('<s>', 'man', 'condemned', 'again', 'NEW', 'fallen', 'at', 'the', 'image', 'NEW', 'man', 'condemned', 'again', 'of', 'pain', 'NEW', 'i', 'am', 'the', 'son', 'of', 'the', 'earth', 'NEW', 'pain', '!', '</s>')]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kneser_ney_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\ngram.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     test_data \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mngrams(lyric_test_tokens,  pad_right\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pad_left\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, left_pad_symbol\u001b[39m=\u001b[39mSENTENCE_BEGIN, right_pad_symbol\u001b[39m=\u001b[39mSENTENCE_END, n\u001b[39m=\u001b[39mNGRAM)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     \u001b[39mprint\u001b[39m([\u001b[39mtuple\u001b[39m(lyric_test_tokens)])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X13sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mprint\u001b[39m(kneser_ney_model\u001b[39m.\u001b[39mperplexity([\u001b[39mtuple\u001b[39m(lyric_test_tokens)]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X13sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     perplexities\u001b[39m.\u001b[39mappend(kneser_ney_model\u001b[39m.\u001b[39mperplexity([\u001b[39mtuple\u001b[39m(lyric_test_tokens)]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/ngram.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m np\u001b[39m.\u001b[39mmedian(perplexities)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kneser_ney_model' is not defined"
     ]
    }
   ],
   "source": [
    "perplexities = []\n",
    "\n",
    "for lyric in test_lyrics:\n",
    "    lyric_test_tokens = utils.tokenize_line(lyric, 2)\n",
    "    print(lyric_test_tokens)\n",
    "\n",
    "    #test_ngrams = list(nltk.bigrams(nltk.lm.preprocessing.pad_both_ends(lyric.split(' '), n=2)))\n",
    "    test_ngrams = list(nltk.bigrams(lyric_test_tokens,  pad_right=True, pad_left=True, left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"))\n",
    "    print(list(test_ngrams))\n",
    "\n",
    "    #test_ngrams = [('<s>',), ('<s>',)]\n",
    "    #grams = list(nltk.ngrams(nltk.lm.preprocessing.pad_both_ends(lyric.split(), n=NGRAM-1), n=NGRAM))\n",
    "    #grams = [('<UNK>', 'hello')]\n",
    "    \n",
    "    print([tuple(lyric_test_tokens)])\n",
    "    print(kneser_ney_model.perplexity([tuple(lyric_test_tokens)]))\n",
    "    perplexities.append(kneser_ney_model.perplexity([tuple(lyric_test_tokens)]))\n",
    "\n",
    "np.median(perplexities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Own N-Gram Language Model with Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_laplace_model(sequences: list, ngram: int = NGRAM, verbose: bool = True):\n",
    "\t\"\"\"\n",
    "\t Creates a trained n-gram language model using Laplace Smoothing. Model will be trained on songs in the given \n",
    "\t music genre. \n",
    "\n",
    "\t Args:\n",
    "\t\tsequences (list): a list of training sequence strings, not tokenized\n",
    "\t\tngram (int): the n-gram order of the language model to create\n",
    "\t\tverbose (bool): if True, prints information about the training data \n",
    "\n",
    "\tReturns:\n",
    "\t\tA trained NGramLaplaceLanguageModel\n",
    "\t\"\"\"\n",
    "\ttokens = utils.tokenize(sequences, ngram)\n",
    "\tmodel = lm.NGramLaplaceLanguageModel(ngram)\n",
    "\tmodel.train(tokens, verbose=verbose)\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 4352028\n",
      "N-gram examples: [('<s>', '<s>', 'become'), ('<s>', 'become', 'one'), ('become', 'one', 'with'), ('one', 'with', 'imagination'), ('with', 'imagination', 'NEW')]\n",
      "Vocabulary Size: 26552\n"
     ]
    }
   ],
   "source": [
    "laplace_model = create_ngram_laplace_model(train_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Generated Lyrics: Heavy Metal \n",
      "\n",
      "a medication for the last breath 's in the ruthless cold\n",
      "valhalla , i 'm god everybody dies\n",
      "\n",
      "damned whore\n",
      "strip me down\n",
      "into the looking glass\n",
      "\n",
      "what can i come to life\n",
      "take my horse\n",
      "i want you at the window , know it 's the stars\n",
      "looking for a sign\n",
      "that the pain and the hare he bounds across the world\n",
      "the mad dog howling at the start till the end of my confusion\n",
      "out of my pain\n",
      "have a gun\n",
      "the anger\n",
      "cruelty\n",
      "\n",
      "thanks for the loss sinks in fear\n",
      "\n",
      "( solo )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_SEQ = 5\n",
    "\n",
    "# Generate lines and print them out \n",
    "print(\"Sample Generated Lyrics:\", GENRE, \"\\n\")\n",
    "for i in range(NUM_SEQ):\n",
    "    lyric_tokens = laplace_model.generate_sentence()\n",
    "    print(clean_lyric(lyric_tokens))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nSample Generated Lyrics: Heavy Metal\\n\\nthe seeking calm\\nyou 're killing us ,\\nyou 're breaking us ,\\nto all these meaningless feelings\\nyou 're countdown , you oooeh suicide momentary with thoughts and narration\\nlove is gone\\nwhen i try to open up my heart\\ndo you hear me now ?\\nthere 's a soul reaching out in fear\\nno reply in the time were here\\nthere 's a soul reaching out in fear\\nso stand up and be satisfaction\\nas a man he was a danger to himself\\nit should be all we talk about\\ngot me so i do n't know torn away\\n\\n\\nSample Generated Lyrics: Pop\\na million eyes stare into space\\nand she 'll always be my macarroni girl\\nwe 'll be alright\\nis it the only defense against the wilderness ?\\ni am your lover-to-be\\ni ca n't take it\\ni wrecking with you once upon a love\\ncome over\\nin the spirit of loves –\\ncause baby i\\nbreak\\ni 'm infected tonight\\nany night , any day\\none foot in front of the other\\nyou 're gon na be all right\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sample Generated Lyrics: Heavy Metal\n",
    "\n",
    "the seeking calm\n",
    "you 're killing us ,\n",
    "you 're breaking us ,\n",
    "to all these meaningless feelings\n",
    "you 're countdown , you oooeh suicide momentary with thoughts and narration\n",
    "love is gone\n",
    "when i try to open up my heart\n",
    "do you hear me now ?\n",
    "there 's a soul reaching out in fear\n",
    "no reply in the time were here\n",
    "there 's a soul reaching out in fear\n",
    "so stand up and be satisfaction\n",
    "as a man he was a danger to himself\n",
    "it should be all we talk about\n",
    "got me so i do n't know torn away\n",
    "\n",
    "\n",
    "Sample Generated Lyrics: Pop\n",
    "a million eyes stare into space\n",
    "and she 'll always be my macarroni girl\n",
    "we 'll be alright\n",
    "is it the only defense against the wilderness ?\n",
    "i am your lover-to-be\n",
    "i ca n't take it\n",
    "i wrecking with you once upon a love\n",
    "come over\n",
    "in the spirit of loves –\n",
    "cause baby i\n",
    "break\n",
    "i 'm infected tonight\n",
    "any night , any day\n",
    "one foot in front of the other\n",
    "you 're gon na be all right\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.0527937128197\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE PERPLEXITY \n",
    "def laplace_evaluate_perplexity(model, test_lines: list, ngram: int=NGRAM): \n",
    "    \"\"\"\n",
    "    Evaluates the given model by finding  the average perplexity of the given test sequences. \n",
    "    \"\"\"\n",
    "    perplexities = []\n",
    "\n",
    "    for line in test_lines:\n",
    "        test_tokens = utils.tokenize_line(line, ngram)\n",
    "        perplexities.append(laplace_model.perplexity(test_tokens))\n",
    "\n",
    "    return np.mean(perplexities)\n",
    "\n",
    "\n",
    "print(laplace_evaluate_perplexity(laplace_model, test_lyrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
