{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing \n",
    "\n",
    "This notebook reads in the raw datasets, drops and renames columns, and merges the lyric and artist data together. We also retrieve Country and Heavy Metal lyrics, which we split into train, validation, and test sets for our models to share. \n",
    "\n",
    "This notebook can be run as-is to produce and save a CSV with all of our cleaned data as well as the genre-specific train/validation/test CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils \n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Lyric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in lyrics data\n",
    "lyrics_df = pd.read_csv('data/lyrics-data.csv')\n",
    "\n",
    "# preview the raw data \n",
    "print(lyrics_df.shape)\n",
    "lyrics_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_artist_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Formats the column with the artist's name. Ensures that this column is formatted consistently, \n",
    "    as it will be used to merge datasets.\n",
    "    Old format is '/firstname-lastname/', update to 'firstname lastname' \n",
    "    \"\"\"\n",
    "    name = name.lower()\n",
    "    name = name.replace('-', ' ')\n",
    "    name = name.replace('/', '')\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and drop unnecessary ones \n",
    "lyrics_df.rename(columns={'SName': 'song_name', 'Lyric': 'lyrics', 'ALink': 'artist'}, inplace = True)\n",
    "lyrics_df.drop(columns=['SLink'], inplace=True) \n",
    "lyrics_df.dropna(inplace=True)\n",
    "\n",
    "# clean the artist name\n",
    "lyrics_df['artist'] = lyrics_df['artist'].apply(clean_artist_name)\n",
    "\n",
    "# only keep songs in English\n",
    "lyrics_df = lyrics_df[lyrics_df['language'] == 'en']\n",
    "\n",
    "# print info about the cleaned lyric data \n",
    "print(lyrics_df.shape)\n",
    "lyrics_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format Artist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in artist data\n",
    "artist_df = pd.read_csv('data/artists-data.csv')\n",
    "\n",
    "# preview the raw data \n",
    "artist_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns and drop unnecessary ones \n",
    "artist_df.rename(columns={'Artist': 'artist', 'Genres': 'genres'}, inplace = True)\n",
    "artist_df.drop(columns=['Popularity', 'Link', 'Songs'], inplace = True)\n",
    "artist_df.dropna(inplace=True)\n",
    "\n",
    "# clean the artist name\n",
    "artist_df['artist'] = artist_df['artist'].apply(clean_artist_name)\n",
    "\n",
    "# print out info about cleaned data \n",
    "print(artist_df.shape)\n",
    "artist_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge Lyric and Artist Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets \n",
    "df = pd.merge(lyrics_df, artist_df, on='artist', how='inner')\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# turn genres into list\n",
    "df['genres'] = df['genres'].apply(lambda genres: genres.split(';'))\n",
    "df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "# print out info on merged dataset \n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv\n",
    "df.to_csv('data/clean_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create separate train, validation, and test datasets to be shared across models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics_in_genre(df: pd.DataFrame, genre: str) -> list:\n",
    "\t\"\"\"\n",
    "\t Returns the lyrics of songs in df with the given genre.\n",
    "\n",
    "\t Args:\n",
    "\t\t\tdf (pandas DataFrame): dataframe of artist and lyric data\n",
    "\t\t\tgenre (str): a music genre found in df\n",
    "\t\tReturns:\n",
    "\t\t\tA list of song lyrics, where each string is a single song\n",
    "\t\"\"\" \n",
    "\tgenre_df = df[df['genres'].apply(lambda x: genre in x)]\n",
    "\treturn genre_df['lyrics'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_songs = get_lyrics_in_genre(df, \"Country\")\n",
    "print(\"Number of Country Songs:\", len(country_songs))\n",
    "\n",
    "metal_songs = get_lyrics_in_genre(df, \"Heavy Metal\")\n",
    "print(\"Number of Heavy Metal Songs:\", len(metal_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle songs and split into 80/10/10 train/val/test sets \n",
    "# we make our train/val/test splits here to ensure that the different sets do not have lyrics from the same song \n",
    "# (ensuring that the model does not see our validation or test data beforehand due to repetitive lyrics)\n",
    "\n",
    "country_train, country_other = train_test_split(country_songs, train_size=.8, random_state=42) # split 80% / 20% \n",
    "country_val, country_test = train_test_split(country_other, train_size=.5, random_state=42) # split remaining 20% 50/50\n",
    "\n",
    "# check sizes \n",
    "print(\"Country song splits:\", len(country_train), len(country_val), len(country_test))\n",
    "\n",
    "metal_train, metal_other = train_test_split(metal_songs, train_size=.8, random_state=42) # split 80% / 20% \n",
    "metal_val, metal_test = train_test_split(metal_other, train_size=.5, random_state=42) # split remaining 20% 50/50\n",
    "\n",
    "# check sizes \n",
    "print(\"Heavy Metal song splits:\", len(metal_train), len(metal_val), len(metal_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the songs into lines \n",
    "country_train_lines = utils.split_songs_into_lines(country_train)\n",
    "country_val_lines = utils.split_songs_into_lines(country_val)\n",
    "country_test_lines = utils.split_songs_into_lines(country_test)\n",
    "print(\"Country line counts:\", len(country_train_lines), len(country_val_lines), len(country_test_lines))\n",
    "\n",
    "\n",
    "metal_train_lines = utils.split_songs_into_lines(metal_train)\n",
    "metal_val_lines = utils.split_songs_into_lines(metal_val)\n",
    "metal_test_lines = utils.split_songs_into_lines(metal_test)\n",
    "print(\"Heavy Metal line counts:\", len(metal_train_lines), len(metal_val_lines), len(metal_test_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a consistent number of samples per genre -- limit by lowest count\n",
    "train_line_count = min(len(country_train_lines), len(metal_train_lines))\n",
    "val_line_count = min(len(country_val_lines), len(metal_val_lines))\n",
    "test_line_count = min(len(country_test_lines), len(metal_test_lines))\n",
    "\n",
    "country_train_lines = country_train_lines[:train_line_count]\n",
    "country_val_lines = country_val_lines[:val_line_count]\n",
    "country_test_lines = country_test_lines[:test_line_count]\n",
    "print(\"Country line counts:\", len(country_train_lines), len(country_val_lines), len(country_test_lines))\n",
    "\n",
    "metal_train_lines = metal_train_lines[:train_line_count]\n",
    "metal_val_lines = metal_val_lines[:val_line_count]\n",
    "metal_test_lines = metal_test_lines[:test_line_count]\n",
    "print(\"Heavy Metal line counts:\", len(metal_train_lines), len(metal_val_lines), len(metal_test_lines))\n",
    "\n",
    "print()\n",
    "print(\"Country line example:\", country_train_lines[0])\n",
    "print(\"Heavy Metal line example:\", metal_train_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation and test data, limit each line to 10 tokens \n",
    "# (lines longer than this are likely due to inconsistent newline formatting and will inflate our perplexity)\n",
    "# further, the gpt2 model sets all sequences to length 10, so we'd like to be more consistent between models \n",
    "# leave train data as-is to potentially give more text to train on \n",
    "def truncate_lines(lines: list, max_length: int=10) -> list:\n",
    "    \"\"\"\n",
    "    Limits each line to the first max_length tokens\n",
    "\n",
    "    Args:\n",
    "        lines (list): a list of strings representing individual lines in a song\n",
    "        max_length (int): the number of tokens to keep from each line\n",
    "\n",
    "    Returns:\n",
    "        The given lines, truncated to the given length\n",
    "    \"\"\"\n",
    "    tokenized_lines = [nltk.word_tokenize(line)[:max_length] for line in lines]\n",
    "    return [' '.join(line) for line in tokenized_lines]\n",
    "\n",
    "country_val_lines = truncate_lines(country_val_lines)\n",
    "country_test_lines = truncate_lines(country_test_lines)\n",
    "metal_val_lines = truncate_lines(metal_val_lines)\n",
    "metal_test_lines = truncate_lines(metal_test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to CSVs to be used across models \n",
    "pd.Series(country_train_lines).to_csv('data/country_train.csv', index=False, header=False)\n",
    "pd.Series(country_val_lines).to_csv('data/country_val.csv', index=False, header=False)\n",
    "pd.Series(country_test_lines).to_csv('data/country_test.csv', index=False, header=False)\n",
    "\n",
    "pd.Series(metal_train_lines).to_csv('data/metal_train.csv', index=False, header=False)\n",
    "pd.Series(metal_val_lines).to_csv('data/metal_val.csv', index=False, header=False)\n",
    "pd.Series(metal_test_lines).to_csv('data/metal_test.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
