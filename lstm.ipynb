{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN with LSTMs Language Model using Skip-Gram Dense Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "from itertools import chain\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Masking\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "SENTENCE_BEGIN = \"<s>\"\n",
    "SENTENCE_END = \"</s>\"\n",
    "PADDING = '<pad>'\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "# hyperparameters  \n",
    "EMBEDDINGS_SIZE = 100\n",
    "BATCH_SIZE = 128\n",
    "SEQUENCE_LENGTH = 10\n",
    "\n",
    "# filepaths \n",
    "TRAIN_FILEPATH = \"country_train.csv\"\n",
    "VAL_FILEPATH = \"country_val.csv\"\n",
    "\n",
    "#TRAIN_FILEPATH = \"metal_train.csv\"\n",
    "#VAL_FILEPATH = \"metal_val.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training lines: 149771\n",
      "Number of validation lines: 18610\n",
      "Lyric Example: i've seen how you tremble whenever he walks through your mind\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "train_lyrics = pd.read_csv(TRAIN_FILEPATH, header=None)[0].to_list()\n",
    "val_lyrics = pd.read_csv(VAL_FILEPATH, header=None)[0].to_list()\n",
    "print(\"Number of training lines:\", len(train_lyrics))\n",
    "print(\"Number of validation lines:\", len(val_lyrics))\n",
    "print('Lyric Example:', train_lyrics[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation: Tokenize Lyrics, Pad Sequences, Create Dense Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a single sentence start and end token around each sequence \n",
    "# TODO remove \n",
    "# TEST\n",
    "#train_lyrics = train_lyrics[:10000]\n",
    "#val_lyrics = val_lyrics[:2000]\n",
    "\n",
    "# REAL\n",
    "#train_lyrics = train_lyrics[:70000]\n",
    "#val_lyrics = val_lyrics[:10000]\n",
    "\n",
    "train_tokens = [utils.tokenize_line(line, ngram=1) for line in train_lyrics] \n",
    "val_tokens = [utils.tokenize_line(line, ngram=1) for line in val_lyrics] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Length: 10.021025432159764\n",
      "Median Length: 10.0\n",
      "90th Percentile Length: 15.0\n",
      "Max Length: 246\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot lengths of lyric lines to determine an appropriate length to pad/truncate to\n",
    "train_sequence_lengths = [len(seq) for seq in train_tokens]\n",
    "\n",
    "print(\"Mean Length:\", np.mean(train_sequence_lengths))\n",
    "print(\"Median Length:\", np.median(train_sequence_lengths))\n",
    "print(\"90th Percentile Length:\", np.percentile(train_sequence_lengths, 90))\n",
    "print(\"Max Length:\", np.max(train_sequence_lengths))\n",
    "\n",
    "plt.hist(train_sequence_lengths, bins=50)\n",
    "plt.xlabel(\"Length of Lyric Line\")\n",
    "plt.ylabel(\"Number of Lines\")\n",
    "plt.title(\"Distribution of Line Length for Lyrics in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 149771\n",
      "Length of Sequences: 10\n"
     ]
    }
   ],
   "source": [
    "def adjust_sequence_length(tokenized_seqs: list, sequence_length: int = SEQUENCE_LENGTH) -> list:\n",
    "    \"\"\"\n",
    "    Pads or truncates all sequences in the provided list to the same length. \n",
    "    Adds or removes tokens from the right side of the sequence.\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "        sequence_length (int): The desired length for all of the sequences\n",
    "        padding_token (str): The token that should be used to pad short sequences to the proper length\n",
    "\n",
    "    Returns:\n",
    "        size_adjusted_sequences (list): A list of lists of tokens, where each inner list is the same length\n",
    "    \"\"\"\n",
    "    size_adjusted_sequences = []\n",
    "    for sequence in tokenized_seqs:\n",
    "        if len(sequence) < sequence_length:\n",
    "            # too short, add padding\n",
    "            num_padding = sequence_length - len(sequence)\n",
    "            size_adjusted_sequences.append( ([PADDING] * num_padding) + sequence)\n",
    "            #size_adjusted_sequences.append(sequence + ([PADDING] * num_padding))\n",
    "        else:\n",
    "            # truncate sequences longer than the chosen length. Keep SENTENCE_END tokens to ensure sentences terminate \n",
    "            size_adjusted_sequences.append(sequence[:sequence_length])\n",
    "\n",
    "    return size_adjusted_sequences\n",
    "\n",
    "\n",
    "def replace_unknowns_train(tokenized_seqs: list) -> list:\n",
    "    \"\"\"\"\n",
    "    Replaces words that occur only once with an UNK token\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "\n",
    "    Returns:\n",
    "        Tokenized sequences with low frequency words replaced with the unknown special token \n",
    "    \"\"\"\n",
    "    # concatenate all sequences together \n",
    "    all_tokens = list(chain(*tokenized_seqs))\n",
    "    token_counts = Counter(all_tokens)\n",
    "\n",
    "    # Replace words with low frequencies to UNK so that we can calculate perplexity on test data with unknown words \n",
    "    cleaned_tokenized_seqs = []\n",
    "    for seq in tokenized_seqs:\n",
    "        cleaned_seq = [tok if token_counts[tok] > 1 else UNK for tok in seq]\n",
    "        cleaned_tokenized_seqs.append(cleaned_seq)\n",
    "\n",
    "    return cleaned_tokenized_seqs\n",
    "\n",
    "\n",
    "size_adjusted_sequences_train = adjust_sequence_length(train_tokens)\n",
    "cleaned_sequences_train = replace_unknowns_train(size_adjusted_sequences_train)\n",
    "print(\"Number of sequences:\", len(cleaned_sequences_train))\n",
    "print(\"Length of Sequences:\", len(cleaned_sequences_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 10610\n",
      "encoded examples: \n",
      " [2, 4, 45, 305, 81, 6, 4212, 1035, 37, 1259] \n",
      " [2, 4213, 49, 1306, 16, 1133, 49, 27, 148, 3]\n"
     ]
    }
   ],
   "source": [
    "# Use Tokenizer to map each token to a unique index \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_sequences_train)\n",
    "encoded_sequences_train = tokenizer.texts_to_sequences(cleaned_sequences_train)\n",
    "\n",
    "print(\"Vocab Size:\", len(tokenizer.word_index))\n",
    "print('encoded examples:', '\\n', encoded_sequences_train[0], '\\n', encoded_sequences_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size for word embeddings: 10610\n"
     ]
    }
   ],
   "source": [
    "# create word embeddings using skip gram algorithm\n",
    "word_embeddings = Word2Vec(sentences=cleaned_sequences_train, vector_size=EMBEDDINGS_SIZE, window=5, sg=1, min_count=1)\n",
    "print('Vocab size for word embeddings:', len(word_embeddings.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gives mappings from words to their embeddings and  \n",
    "# indexes from the tokenizers to their embeddings\n",
    "\n",
    "def map_embeddings(embeddings: Word2Vec, tokenizer: Tokenizer) -> (dict, dict):\n",
    "    ''' Creates mappings between different token representations \n",
    "    Arguments:\n",
    "        embeddings: Word2Vec word embeddings for the data (maps tokens to embedding vectors)\n",
    "        tokenizer: Tokenizer used to tokenize the data (maps token to index)\n",
    "    Returns:\n",
    "        (dict): mapping from word to its embedding vector\n",
    "        (dict): mapping from index to its embedding vector\n",
    "    '''\n",
    "    # initialize dictionaries \n",
    "    token_to_embedding = {}\n",
    "    index_to_embedding = {}\n",
    "\n",
    "    # tokenizer maps tokens to unique indices \n",
    "    for token, index in tokenizer.word_index.items():\n",
    "        embedding = embeddings[token]\n",
    "\n",
    "        token_to_embedding[token] = embedding\n",
    "        index_to_embedding[index] = embedding\n",
    "\n",
    "    return (token_to_embedding, index_to_embedding)\n",
    "\n",
    "\n",
    "token_to_embedding, index_to_embedding = map_embeddings(word_embeddings.wv, tokenizer)\n",
    "\n",
    "# Set embedding associated with padding token to all zeros -- will be used to mask this token\n",
    "#padding_index = tokenizer.word_index.get(PADDING)\n",
    "#index_to_embedding[padding_index] = [0] * EMBEDDINGS_SIZE\n",
    "#token_to_embedding[PADDING] = [0] * EMBEDDINGS_SIZE\n",
    "\n",
    "# Fill in unused index zero to avoid dimension mismatch\n",
    "index_to_embedding[0] = [0] * EMBEDDINGS_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Samples for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch shape: (128, 9, 100)\n",
      "y batch shape: (128, 9, 10611)\n"
     ]
    }
   ],
   "source": [
    "def data_generator(data: list, num_sequences_per_batch: int, index_2_embedding: dict) -> (np.array, np.array):\n",
    "    '''\n",
    "    Returns a data generator to train the neural network in batches\n",
    "\n",
    "    X data will be represented in embedding form.\n",
    "    Y data will be represented with one hot vectors. \n",
    "\n",
    "    Args:\n",
    "    data (list of lists): tokenized sequences represented by their unique index encodings \n",
    "    num_sequences_per_batch (int): batch size yielded on each iteration of the generator \n",
    "    index_2_embedding (dict): mapping between unique token indices and dense word embeddings \n",
    "\n",
    "    Returns:\n",
    "    X_batch_embeddings (3-D numpy array): sequences of embeddings with dimensions (batch size, num timesteps, embedding size)\n",
    "                                          Take the first (SEQUENCE_LENGTH - 1) tokens of each sequence\n",
    "    y_batch (3-D numpy array): sequences of one hot vectors with dimensions (batch size, num timesteps, vocab size)\n",
    "                                          Take the last (SEQUENCE_LENGTH - 1) tokens of each sequence \n",
    "                                          (X shifted forward one token so that the neural net predicts the next word in the sequence for each timestep)\n",
    "    '''\n",
    "    # iterate over data in batches - stored in the form of unique token indices \n",
    "    i = 0\n",
    "    while True:\n",
    "        # get samples that we'd like to train on for this batch \n",
    "        data_batch = data[i:i+num_sequences_per_batch]\n",
    "\n",
    "        # increment i with each batch \n",
    "        i += num_sequences_per_batch\n",
    "\n",
    "        # split into X and Y -- shifted sequence so that for each timestep, Y is the token that follows X \n",
    "        X = [sequence[:-1] for sequence in data_batch]\n",
    "        Y = [sequence[1:] for sequence in data_batch]\n",
    "\n",
    "        # get embeddings for X data \n",
    "        X_embeddings = []\n",
    "        for X_sequence in X:\n",
    "            X_sequence_embeddings = [index_2_embedding[token_idx] for token_idx in X_sequence]\n",
    "            X_embeddings.append(X_sequence_embeddings)\n",
    "\n",
    "        # get one hot vectors for Y data \n",
    "        Y_one_hot_vectors = []\n",
    "        for Y_sequence in Y:\n",
    "            Y_one_hot = to_categorical(Y_sequence, num_classes=len(index_2_embedding))\n",
    "            Y_one_hot_vectors.append(Y_one_hot)\n",
    "\n",
    "        # yield statement instead of return for generator \n",
    "        yield(np.array(X_embeddings), np.array(Y_one_hot_vectors))\n",
    "\n",
    "\n",
    "# demo the data generator\n",
    "demo_data_generator = data_generator(encoded_sequences_train, BATCH_SIZE, index_to_embedding)\n",
    "demo_sample = next(demo_data_generator)\n",
    "print(\"X batch shape:\", demo_sample[0].shape)\n",
    "print(\"y batch shape:\", demo_sample[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data -- unknown words determined by training vocabulary \n",
    "def encode_val_sequences(tokenized_seqs: list, tokenizer) -> list:\n",
    "    \"\"\"\"\n",
    "    Replaces words that are not in the tokenizer's vocab with the unknown special token and encodes it to \n",
    "    unique token indices specified by the provided Tokenizer.\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "        tokenizer: Tokenizer used maps token to index\n",
    "\n",
    "    Returns:\n",
    "        Encoded sequences with words not in the training vocabulary replaced with the unknown special token \n",
    "    \"\"\"\n",
    "    cleaned_tokenized_seqs = []\n",
    "    for seq in tokenized_seqs:\n",
    "        cleaned_seq = [tok if tok in tokenizer.word_index.keys() else UNK for tok in seq]\n",
    "        cleaned_tokenized_seqs.append(cleaned_seq)\n",
    "\n",
    "    return tokenizer.texts_to_sequences(cleaned_tokenized_seqs)\n",
    "\n",
    "size_adjusted_sequences_val = adjust_sequence_length(val_tokens)\n",
    "encoded_sequences_val = encode_val_sequences(size_adjusted_sequences_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "\n",
    "# chatgpt code when asked \"how can I print perplexity with each epoch of a keras model\"\n",
    "class PerplexityCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(PerplexityCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        x_val, y_val = self.validation_data\n",
    "        y_pred = self.model.predict(x_val)\n",
    "        cross_entropy = -np.sum(np.log(np.clip(y_pred, 1e-10, 1.0)) * y_val) / len(y_val)\n",
    "        perplexity = np.exp(cross_entropy)\n",
    "        print(f'\\nPerplexity on validation data after epoch {epoch + 1}: {perplexity:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_rnn(train_data: np.array,\n",
    "             val_data: np.array, \n",
    "             index_2_embedding: dict, \n",
    "             num_epochs: int=1, \n",
    "             num_sequences_per_batch: int=BATCH_SIZE, \n",
    "             sequence_length: int=SEQUENCE_LENGTH,\n",
    "             embedding_size: int=EMBEDDINGS_SIZE):\n",
    "    \"\"\"\n",
    "    Creates and trains an RNN with LSTM cells using given training data and batch size.\n",
    "\n",
    "    Args:\n",
    "        train_data (list of lists): encoded sequences of training data represented by token indices \n",
    "        train_data (list of lists): encoded sequences of validation data represented by token indices \n",
    "        index_2_embedding (dict): mapping from token index -> word2vec embeddings \n",
    "        num_epochs (int): number of training epochs\n",
    "        num_sequences_per_batch (int): batch size for training data \n",
    "        sequence_length (int): number of tokens in each training sample \n",
    "        embedding_size (int): size of the dense word embeddings used to represent tokens \n",
    "    Returns:\n",
    "        A trained Neural Network language model\n",
    "    \"\"\"\n",
    "    # define model parameters\n",
    "    hidden_units = 200\n",
    "    hidden_input_dim = (sequence_length - 1, embedding_size)      # (number of steps, number of features per step)\n",
    "    output_dim = len(index_2_embedding)                            # vocab size \n",
    "\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    # hidden layer\n",
    "    model.add(Bidirectional(LSTM(hidden_units, \n",
    "                                 input_shape=hidden_input_dim,\n",
    "                                 return_sequences=True)))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=output_dim, activation='softmax'))\n",
    "\n",
    "    # configure the learning process\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"top_k_categorical_accuracy\"])\n",
    "    \n",
    "    # total number of batches per epoch \n",
    "    steps_per_epoch = len(train_data)//num_sequences_per_batch\n",
    "    steps_per_epoch_val = len(val_data)//num_sequences_per_batch\n",
    "\n",
    " \n",
    "   \n",
    "    for i in range(num_epochs):\n",
    "        if i % 5 == 0:\n",
    "            print(\"Epoch\", i)\n",
    "\n",
    "        # create a new data generator for us to iterate through\n",
    "        train_generator = data_generator(train_data, num_sequences_per_batch, index_2_embedding)\n",
    "        val_generator = data_generator(val_data, num_sequences_per_batch, index_2_embedding)\n",
    "        perplexity_callback = PerplexityCallback(validation_data=val_generator)\n",
    "\n",
    "\n",
    "        # train model \n",
    "        model.fit(x=train_generator, steps_per_epoch=steps_per_epoch, validation_data=val_generator, validation_steps=steps_per_epoch_val, callbacks=[perplexity_callback])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1170/1170 [==============================] - 204s 171ms/step - loss: 2.3811 - top_k_categorical_accuracy: 0.7339 - val_loss: 0.8464 - val_top_k_categorical_accuracy: 0.9124\n",
      "1170/1170 [==============================] - 209s 179ms/step - loss: 0.6557 - top_k_categorical_accuracy: 0.9299 - val_loss: 0.5314 - val_top_k_categorical_accuracy: 0.9435\n",
      "1170/1170 [==============================] - 210s 179ms/step - loss: 0.4318 - top_k_categorical_accuracy: 0.9516 - val_loss: 0.4399 - val_top_k_categorical_accuracy: 0.9510\n",
      "1170/1170 [==============================] - 210s 179ms/step - loss: 0.3214 - top_k_categorical_accuracy: 0.9647 - val_loss: 0.4008 - val_top_k_categorical_accuracy: 0.9540\n",
      "1170/1170 [==============================] - 210s 179ms/step - loss: 0.2598 - top_k_categorical_accuracy: 0.9704 - val_loss: 0.3810 - val_top_k_categorical_accuracy: 0.9561\n",
      "Epoch 5\n",
      "1170/1170 [==============================] - 213s 182ms/step - loss: 0.2254 - top_k_categorical_accuracy: 0.9724 - val_loss: 0.3683 - val_top_k_categorical_accuracy: 0.9575\n",
      "1170/1170 [==============================] - 219s 187ms/step - loss: 0.2040 - top_k_categorical_accuracy: 0.9740 - val_loss: 0.3618 - val_top_k_categorical_accuracy: 0.9583\n",
      "1170/1170 [==============================] - 212s 181ms/step - loss: 0.1885 - top_k_categorical_accuracy: 0.9757 - val_loss: 0.3584 - val_top_k_categorical_accuracy: 0.9585\n",
      "1170/1170 [==============================] - 206s 176ms/step - loss: 0.1758 - top_k_categorical_accuracy: 0.9775 - val_loss: 0.3575 - val_top_k_categorical_accuracy: 0.9590\n",
      "1170/1170 [==============================] - 214s 183ms/step - loss: 0.1645 - top_k_categorical_accuracy: 0.9793 - val_loss: 0.3601 - val_top_k_categorical_accuracy: 0.9588\n",
      "Epoch 10\n",
      "1170/1170 [==============================] - 216s 185ms/step - loss: 0.1544 - top_k_categorical_accuracy: 0.9809 - val_loss: 0.3629 - val_top_k_categorical_accuracy: 0.9584\n",
      "1170/1170 [==============================] - 217s 185ms/step - loss: 0.1457 - top_k_categorical_accuracy: 0.9824 - val_loss: 0.3605 - val_top_k_categorical_accuracy: 0.9590\n",
      "1170/1170 [==============================] - 211s 180ms/step - loss: 0.1374 - top_k_categorical_accuracy: 0.9836 - val_loss: 0.3590 - val_top_k_categorical_accuracy: 0.9600\n",
      "1170/1170 [==============================] - 214s 183ms/step - loss: 0.1301 - top_k_categorical_accuracy: 0.9848 - val_loss: 0.3603 - val_top_k_categorical_accuracy: 0.9600\n",
      "1170/1170 [==============================] - 211s 180ms/step - loss: 0.1244 - top_k_categorical_accuracy: 0.9858 - val_loss: 0.3632 - val_top_k_categorical_accuracy: 0.9601\n",
      "Epoch 15\n",
      "1170/1170 [==============================] - 210s 179ms/step - loss: 0.1178 - top_k_categorical_accuracy: 0.9867 - val_loss: 0.3706 - val_top_k_categorical_accuracy: 0.9591\n",
      "1170/1170 [==============================] - 214s 183ms/step - loss: 0.1127 - top_k_categorical_accuracy: 0.9876 - val_loss: 0.3787 - val_top_k_categorical_accuracy: 0.9587\n",
      "1170/1170 [==============================] - 212s 181ms/step - loss: 0.1077 - top_k_categorical_accuracy: 0.9883 - val_loss: 0.3750 - val_top_k_categorical_accuracy: 0.9595\n",
      "1170/1170 [==============================] - 213s 182ms/step - loss: 0.1027 - top_k_categorical_accuracy: 0.9890 - val_loss: 0.3791 - val_top_k_categorical_accuracy: 0.9598\n",
      "1170/1170 [==============================] - 214s 183ms/step - loss: 0.0974 - top_k_categorical_accuracy: 0.9897 - val_loss: 0.3811 - val_top_k_categorical_accuracy: 0.9597\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirection  (None, None, 400)         481600    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 10611)       4255011   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4736611 (18.07 MB)\n",
      "Trainable params: 4736611 (18.07 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = lstm_rnn(np.array(encoded_sequences_train), np.array(encoded_sequences_val), index_to_embedding, num_epochs=20)\n",
    "\n",
    "# save trained model \n",
    "# model.save(MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1170/1170 [==============================] - ETA: 0s - loss: 2.3874 - top_k_categorical_accuracy: 0.7329"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_test \u001b[39m=\u001b[39m lstm_rnn(np\u001b[39m.\u001b[39;49marray(encoded_sequences_train), np\u001b[39m.\u001b[39;49marray(encoded_sequences_val), index_to_embedding, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 19\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     perplexity_callback \u001b[39m=\u001b[39m PerplexityCallback(validation_data\u001b[39m=\u001b[39mval_generator)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# train model \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_generator, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch, validation_data\u001b[39m=\u001b[39;49mval_generator, validation_steps\u001b[39m=\u001b[39;49msteps_per_epoch_val, callbacks\u001b[39m=\u001b[39;49m[perplexity_callback])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     x_val, y_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_data\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(x_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X40sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     cross_entropy \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(np\u001b[39m.\u001b[39mclip(y_pred, \u001b[39m1e-10\u001b[39m, \u001b[39m1.0\u001b[39m)) \u001b[39m*\u001b[39m y_val) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_val)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model_test = lstm_rnn(np.array(encoded_sequences_train), np.array(encoded_sequences_val), index_to_embedding, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create functions to generate new sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(model: Sequential, \n",
    "                      tokenizer: Tokenizer, \n",
    "                      index_2_embedding: dict, \n",
    "                      num_seq: int):\n",
    "    '''\n",
    "    Generates a given number of sequences using the given RNN language model.\n",
    "    Will begin the sequence generation with n-1 SENTENCE_BEGIN tokens.\n",
    "    Returned sequences will have the BEGIN, END, and PADDING tokens removed\n",
    "\n",
    "    Args:\n",
    "        model: RNN language model\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        index_2_embedding: mapping from token index -> word2vec embeddings \n",
    "        num_seq: the number of sequences to generate \n",
    "\n",
    "    Returns: \n",
    "        A list of strings, where each string is a generated sequence with special tokens removed \n",
    "    '''\n",
    "    seed = [SENTENCE_BEGIN] * (SEQUENCE_LENGTH - 1) #([PADDING] * (SEQUENCE_LENGTH - 1)) + [SENTENCE_BEGIN]\n",
    "    \n",
    "    sequences = []\n",
    "    for _ in range(num_seq):\n",
    "        seq = generate_seq(model, tokenizer, index_2_embedding, seed)\n",
    "        seq = ' '.join(seq)\n",
    "\n",
    "        # remove special tokens\n",
    "        seq = seq.replace(SENTENCE_BEGIN, '')\n",
    "        seq = seq.replace(SENTENCE_END, '')\n",
    "        seq = seq.replace(PADDING, '')\n",
    "\n",
    "        sequences.append(seq.strip())\n",
    "        \n",
    "    return sequences\n",
    "\n",
    "\n",
    "\n",
    "def generate_seq(model: Sequential, \n",
    "                 tokenizer: Tokenizer, \n",
    "                 index_2_embedding: dict, \n",
    "                 seed: list):\n",
    "    '''\n",
    "    Generates a single sequence using the given model starting with a SENTENCE_BEGIN and ending with a SENTENCE_END token. \n",
    "    Since an RNN takes input sequences of fixed length, use a sliding window to continually predict the next word. \n",
    "\n",
    "    Args:\n",
    "        model: RNN language model\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        index_2_embedding: mapping from token index -> word2vec embeddings \n",
    "        seed: the initial tokens to feed the RNN\n",
    "    Returns: \n",
    "        An array of tokens representing a sequence \n",
    "    '''\n",
    "    padding_index = tokenizer.word_index.get(PADDING)\n",
    "    sentence_begin_index = tokenizer.word_index.get(SENTENCE_BEGIN)\n",
    "    sentence_end_index = tokenizer.word_index.get(SENTENCE_END)\n",
    "\n",
    "    # track the unique token indices for the sequence \n",
    "    sequence_indices = [tokenizer.word_index.get(tok) for tok in seed] \n",
    "\n",
    "    input_length = SEQUENCE_LENGTH - 1\n",
    "\n",
    "    # until we get a SENTENCE_END token\n",
    "    while sequence_indices[-1] != sentence_end_index and len(sequence_indices) < 30:\n",
    "        # get latest tokens to use as inputs \n",
    "        input_sequence = sequence_indices[-1*input_length:]\n",
    "\n",
    "        # convert the input sequence to embeddings\n",
    "        input_embeddings = np.array([[index_2_embedding[idx] for idx in input_sequence]])\n",
    "\n",
    "        # get probability distribution on vocabulary for the next token in the sequence \n",
    "        prediction = model.predict(input_embeddings, verbose=False)[0][-1]\n",
    "\n",
    "        # sample from the probability distribution \n",
    "        next_tok_idx = np.random.choice(len(prediction), p=prediction)\n",
    "\n",
    "        # skip mid-sentence SENTENCE_BEGIN and PADDING tokens\n",
    "        if next_tok_idx == sentence_begin_index or next_tok_idx == padding_index:\n",
    "            continue\n",
    "\n",
    "        # add newly generated token to our sequence \n",
    "        sequence_indices.append(next_tok_idx)\n",
    "\n",
    "    # convert to words \n",
    "    tokenizer_words = list(tokenizer.word_index.keys())\n",
    "    tokenizer_indices = list(tokenizer.word_index.values())\n",
    "    sequence = [tokenizer_words[tokenizer_indices.index(idx)] for idx in sequence_indices]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Generated Lyrics:\n",
      "\n",
      "bad in their will never\n",
      "still about how they changed\n",
      "give my whole hand in\n",
      "'' , do n't know why why why is i say ya say\n",
      "<unk> yet will be how they 're a man that hurts a memory is yet ca n't take that angels sing\n",
      "love ever give to me little\n",
      "i take her the man that to live in memory someday how we make along stop mad somehow get wild we\n",
      "do n't know that bad '' please you say again we 're gon na make it head sings steele , that\n",
      "about the bad ''\n",
      "`` do n't know\n"
     ]
    }
   ],
   "source": [
    "# load in model \n",
    "model = keras.saving.load_model(\"country_lstm_model_epoch20_full\")\n",
    "# Generate new lyrics \n",
    "generated_sequences = generate_sequences(model, tokenizer, index_to_embedding, num_seq=10)\n",
    "print(\"Sample Generated Lyrics:\\n\")\n",
    "for seq in generated_sequences:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Generated Lyrics:\n",
      "\n",
      "to ' lord century\n",
      "no\n",
      "no says lord neighbors\n",
      "that says\n",
      "deeper know deeper\n",
      "that room\n",
      "that them like be felt maybe\n",
      "workin on work on hiding stranger down be\n",
      "across things wan work hide but be a flies who myself she man day taste go dance finally simple swear second-hand\n",
      "man ?\n"
     ]
    }
   ],
   "source": [
    "model = keras.saving.load_model(\"country_lstm_model_epoch20\")\n",
    "# Generate new lyrics \n",
    "generated_sequences = generate_sequences(model, tokenizer, index_to_embedding, num_seq=10)\n",
    "print(\"Sample Generated Lyrics:\\n\")\n",
    "for seq in generated_sequences:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Perplexity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998134\n",
      "0.999814\n",
      "0.9998591\n",
      "0.9998958\n",
      "0.96978104\n",
      "0.9867394\n",
      "0.9575446\n",
      "0.9834636\n",
      "0.082679674\n",
      "0\n",
      "0.69197285\n",
      "0.99948776\n",
      "0.99854666\n",
      "0.999757\n",
      "0.99705964\n",
      "0.9958288\n",
      "0.9575031\n",
      "3.0464173e-05\n",
      "0.41098762\n",
      "0\n",
      "0.9994178\n",
      "0.999788\n",
      "0.8989352\n",
      "0.99948967\n",
      "0.92509687\n",
      "0.4224358\n",
      "0.0028732703\n",
      "0.99898976\n",
      "0.001201606\n",
      "0\n",
      "0.99635446\n",
      "0.99899906\n",
      "0.99988985\n",
      "0.99661154\n",
      "0.9999534\n",
      "0.99127954\n",
      "0.9985297\n",
      "0.9984465\n",
      "0.27420285\n",
      "0\n",
      "0.9989568\n",
      "0.9987092\n",
      "0.99825853\n",
      "0.995641\n",
      "0.9945479\n",
      "0.76706433\n",
      "0.2949928\n",
      "0.047940303\n",
      "0.9999589\n",
      "0\n",
      "0.9566376\n",
      "0.45805696\n",
      "0.80449027\n",
      "0.9449063\n",
      "0.99339527\n",
      "0.96681464\n",
      "0.99618137\n",
      "0.9690155\n",
      "0.00060813676\n",
      "0\n",
      "0.93606246\n",
      "0.9999441\n",
      "0.9759237\n",
      "0.97739536\n",
      "0.8911503\n",
      "0.99853575\n",
      "0.56052566\n",
      "0.9999541\n",
      "0.016630758\n",
      "0\n",
      "0.9970067\n",
      "0.99881893\n",
      "0.99797124\n",
      "0.996761\n",
      "0.759718\n",
      "0.99926525\n",
      "0.99977\n",
      "0.999946\n",
      "0.03874117\n",
      "0\n",
      "0.99635446\n",
      "0.99899906\n",
      "0.99988985\n",
      "0.99661154\n",
      "0.9999534\n",
      "0.99127954\n",
      "0.9985297\n",
      "0.9984465\n",
      "0.27420285\n",
      "0\n",
      "0.9989568\n",
      "0.9987092\n",
      "0.99825853\n",
      "0.995641\n",
      "0.9945479\n",
      "0.76706433\n",
      "0.2949928\n",
      "0.047940303\n",
      "0.9999589\n",
      "0\n",
      "0.9920765\n",
      "0.17991064\n",
      "0.9997124\n",
      "0.76203924\n",
      "0.12797788\n",
      "0.9889235\n",
      "0.99513185\n",
      "0.99741864\n",
      "0.0013295854\n",
      "0\n",
      "0.92317086\n",
      "0.99909437\n",
      "0.9984648\n",
      "0.999795\n",
      "0.9999695\n",
      "0.9921704\n",
      "0.9999769\n",
      "0.66420674\n",
      "0.14187224\n",
      "0\n",
      "0.9516457\n",
      "0.3363963\n",
      "0.9904366\n",
      "0.99706715\n",
      "0.990732\n",
      "0.1296271\n",
      "0.82322866\n",
      "0.9983165\n",
      "0.0015743686\n",
      "0\n",
      "0.9996686\n",
      "0.63639677\n",
      "0.9992588\n",
      "0.8040036\n",
      "0.94948554\n",
      "0.009353907\n",
      "0.9619181\n",
      "0.9885296\n",
      "0.001038219\n",
      "0\n",
      "0.9995697\n",
      "0.9995309\n",
      "0.90732145\n",
      "0.9868984\n",
      "0.9987062\n",
      "0.99986076\n",
      "0.8835194\n",
      "0.3629037\n",
      "0.23096678\n",
      "0\n",
      "0.19267811\n",
      "0.99911946\n",
      "0.99750453\n",
      "0.9999598\n",
      "0.9610865\n",
      "0.99977154\n",
      "0.993115\n",
      "0.99897015\n",
      "0.019330768\n",
      "0\n",
      "0.9989568\n",
      "0.9987092\n",
      "0.99825853\n",
      "0.995641\n",
      "0.9945479\n",
      "0.76706433\n",
      "0.2949928\n",
      "0.047940303\n",
      "0.9999589\n",
      "0\n",
      "0.15729444\n",
      "0.9990748\n",
      "0.9975134\n",
      "0.9999703\n",
      "0.94114375\n",
      "0.99990916\n",
      "0.9971551\n",
      "0.9460638\n",
      "7.388191e-06\n",
      "0\n",
      "0.9989568\n",
      "0.9987092\n",
      "0.99825853\n",
      "0.995641\n",
      "0.9945479\n",
      "0.76706433\n",
      "0.2949928\n",
      "0.047940303\n",
      "0.9999589\n",
      "0\n",
      "0.99907696\n",
      "0.02501512\n",
      "0.99945754\n",
      "0.9538138\n",
      "0.9998832\n",
      "0.8881692\n",
      "0.9990747\n",
      "0.99626786\n",
      "0.99986684\n",
      "0\n",
      "0.9986695\n",
      "0.9997322\n",
      "0.96415216\n",
      "0.9998869\n",
      "0.9957361\n",
      "0.6449831\n",
      "0.9990274\n",
      "0.06417591\n",
      "0.0002111925\n",
      "0\n",
      "0.7232794\n",
      "0.99979264\n",
      "0.9279527\n",
      "0.9695845\n",
      "0.99952316\n",
      "0.77573234\n",
      "0.9986059\n",
      "0.9582368\n",
      "0.31368917\n",
      "0\n",
      "0.99595356\n",
      "0.993526\n",
      "0.35588256\n",
      "0.9995561\n",
      "0.9953825\n",
      "0.9838266\n",
      "0.9803494\n",
      "0.75307435\n",
      "0.99942505\n",
      "0\n",
      "0.9988777\n",
      "0.995598\n",
      "0.9718598\n",
      "0.98874515\n",
      "0.27842888\n",
      "0.22775209\n",
      "0.9995029\n",
      "0.6006745\n",
      "0.9999505\n",
      "0\n",
      "0.98284507\n",
      "0.99992955\n",
      "0.9987118\n",
      "0.66087013\n",
      "0.99983335\n",
      "0.9574353\n",
      "0.9982204\n",
      "0.009399109\n",
      "0.11488776\n",
      "0\n",
      "0.99933404\n",
      "0.9951109\n",
      "0.97850317\n",
      "0.9843976\n",
      "0.9997063\n",
      "0.91301525\n",
      "0.38870567\n",
      "0.3697593\n",
      "0.99995935\n",
      "0\n",
      "0.9217706\n",
      "0.9999478\n",
      "0.9857816\n",
      "0.99641234\n",
      "0.9981494\n",
      "0.7656059\n",
      "0.9755651\n",
      "0.9317047\n",
      "0.0068287575\n",
      "0\n",
      "0.99921286\n",
      "0.9999124\n",
      "0.9691008\n",
      "0.96438473\n",
      "0.91953653\n",
      "0.89247197\n",
      "0.99993634\n",
      "0.9968656\n",
      "0.9999877\n",
      "0\n",
      "0.9992173\n",
      "0.99973387\n",
      "0.14997096\n",
      "0.9999833\n",
      "0.99113\n",
      "0.98904943\n",
      "0.98312527\n",
      "0.99995863\n",
      "0.054859497\n",
      "0\n",
      "0.98768616\n",
      "0.99948907\n",
      "0.60105956\n",
      "0.99327093\n",
      "0.9791085\n",
      "0.43006802\n",
      "0.08874662\n",
      "0.99932885\n",
      "0.018976362\n",
      "0\n",
      "0.9880944\n",
      "0.9240635\n",
      "0.9664205\n",
      "0.92603993\n",
      "0.99787796\n",
      "0.99591905\n",
      "0.71400106\n",
      "0.99799806\n",
      "0.99997723\n",
      "0\n",
      "0.9982462\n",
      "0.99966466\n",
      "0.97317296\n",
      "0.12621973\n",
      "0.99770904\n",
      "0.66400963\n",
      "0.74159634\n",
      "0.9989674\n",
      "0.99999225\n",
      "0\n",
      "0.99960965\n",
      "0.999313\n",
      "0.8529082\n",
      "0.93727696\n",
      "0.981777\n",
      "0.9787891\n",
      "0.3476186\n",
      "0.9284606\n",
      "0.9999999\n",
      "0\n",
      "0.99279755\n",
      "0.10440927\n",
      "0.90831995\n",
      "0.9961941\n",
      "0.77379405\n",
      "0.97755665\n",
      "0.38197425\n",
      "0.26315808\n",
      "0.99997413\n",
      "0\n",
      "0.88810486\n",
      "0.9913566\n",
      "0.99897087\n",
      "0.9983437\n",
      "0.008003252\n",
      "0.8375727\n",
      "0.060539324\n",
      "0.9999876\n",
      "0.0011194807\n",
      "0\n",
      "0.99921286\n",
      "0.9999124\n",
      "0.9691008\n",
      "0.96438473\n",
      "0.91953653\n",
      "0.89247197\n",
      "0.99993634\n",
      "0.9968656\n",
      "0.9999877\n",
      "0\n",
      "0.9840476\n",
      "0.898221\n",
      "0.99186665\n",
      "0.21742752\n",
      "0.96556896\n",
      "0.9991142\n",
      "0.99277616\n",
      "0.28221703\n",
      "0.00044899597\n",
      "0\n",
      "0.9975107\n",
      "0.99770206\n",
      "0.99659747\n",
      "0.62853384\n",
      "0.9990989\n",
      "0.98882794\n",
      "0.9999603\n",
      "0.9877351\n",
      "0.99999285\n",
      "0\n",
      "0.97220314\n",
      "0.95426774\n",
      "0.98027956\n",
      "0.7211637\n",
      "0.99986315\n",
      "0.78722364\n",
      "0.99386\n",
      "0.3440922\n",
      "0.00021088426\n",
      "0\n",
      "0.9980361\n",
      "0.99863905\n",
      "0.9835676\n",
      "0.9937204\n",
      "0.97779214\n",
      "0.818047\n",
      "0.99965584\n",
      "0.99980503\n",
      "0.99991333\n",
      "0\n",
      "0.9980361\n",
      "0.99863905\n",
      "0.9835676\n",
      "0.9937204\n",
      "0.97779214\n",
      "0.818047\n",
      "0.99965584\n",
      "0.99980503\n",
      "0.99991333\n",
      "0\n",
      "0.99728906\n",
      "0.39743993\n",
      "0.7535593\n",
      "0.9990073\n",
      "0.99988496\n",
      "0.91833013\n",
      "0.49355426\n",
      "0.46075076\n",
      "0.0009541636\n",
      "0\n",
      "0.9955213\n",
      "0.9974874\n",
      "0.9977647\n",
      "0.9939448\n",
      "0.08892362\n",
      "0.96683335\n",
      "0.99388885\n",
      "0.8529253\n",
      "0.9999975\n",
      "0\n",
      "0.9998884\n",
      "0.9506529\n",
      "0.99813473\n",
      "0.79871\n",
      "0.9268928\n",
      "0.27305698\n",
      "0.99971527\n",
      "0.82964265\n",
      "0.9999988\n",
      "0\n",
      "0.8360834\n",
      "0.9987085\n",
      "0.9906783\n",
      "0.036583506\n",
      "0.999887\n",
      "0.79887456\n",
      "0.99090695\n",
      "0.9961415\n",
      "0.8605525\n",
      "0\n",
      "0.99950695\n",
      "0.38488823\n",
      "0.16351724\n",
      "0.9997774\n",
      "0.9855042\n",
      "0.98371845\n",
      "0.7548508\n",
      "0.6799054\n",
      "2.7572316e-08\n",
      "0\n",
      "0.99950564\n",
      "0.9994469\n",
      "0.9253783\n",
      "0.9592643\n",
      "0.9797763\n",
      "0.75427157\n",
      "0.025535468\n",
      "0.3149517\n",
      "0.99999464\n",
      "0\n",
      "0.99883395\n",
      "0.9995448\n",
      "0.9988269\n",
      "0.5339614\n",
      "0.99863297\n",
      "0.92596424\n",
      "0.99631363\n",
      "0.05686202\n",
      "0.99999917\n",
      "0\n",
      "0.99898857\n",
      "0.9995117\n",
      "0.9995017\n",
      "0.5966352\n",
      "0.97997653\n",
      "0.98725104\n",
      "0.9998079\n",
      "0.66454107\n",
      "0.9998965\n",
      "0\n",
      "0.9992107\n",
      "0.721429\n",
      "0.99988973\n",
      "0.1349087\n",
      "0.9834975\n",
      "0.97448653\n",
      "0.9977063\n",
      "0.01002304\n",
      "0.9177894\n",
      "0\n",
      "0.9994937\n",
      "0.9983708\n",
      "0.9873546\n",
      "0.9168047\n",
      "0.99828315\n",
      "0.9964143\n",
      "0.9490972\n",
      "0.31862307\n",
      "0.9999988\n",
      "0\n",
      "0.9836278\n",
      "0.91697127\n",
      "0.0060864286\n",
      "0.8395716\n",
      "0.013049777\n",
      "0.99882513\n",
      "0.75444376\n",
      "0.79898393\n",
      "0.5448032\n",
      "0\n",
      "0.99977154\n",
      "0.9919487\n",
      "0.9993555\n",
      "0.99795616\n",
      "0.9995685\n",
      "0.056583066\n",
      "0.88284457\n",
      "0.9996049\n",
      "0.99996305\n",
      "0\n",
      "0.99912053\n",
      "0.99353117\n",
      "0.37041453\n",
      "0.9806935\n",
      "0.5194941\n",
      "0.63119173\n",
      "0.98322046\n",
      "0.07570478\n",
      "0.61646175\n",
      "0\n",
      "0.99977475\n",
      "0.991625\n",
      "0.55124474\n",
      "0.1437899\n",
      "0.0011540314\n",
      "0.9942524\n",
      "0.124477774\n",
      "0.99678\n",
      "0.9999994\n",
      "0\n",
      "0.99837506\n",
      "0.009568373\n",
      "0.46359897\n",
      "0.82326657\n",
      "0.99195284\n",
      "0.76230043\n",
      "0.9968911\n",
      "0.9951508\n",
      "0.66001785\n",
      "0\n",
      "0.9989691\n",
      "0.99777126\n",
      "0.9586951\n",
      "0.9994715\n",
      "0.23348084\n",
      "0.9815685\n",
      "0.8253204\n",
      "0.886791\n",
      "0.9975526\n",
      "0\n",
      "0.9989987\n",
      "0.9994586\n",
      "0.9985689\n",
      "0.40801495\n",
      "0.9821394\n",
      "0.90625256\n",
      "0.9988838\n",
      "0.91727877\n",
      "0.99976236\n",
      "0\n",
      "0.99063957\n",
      "0.9903375\n",
      "0.9966407\n",
      "0.44190702\n",
      "0.96573645\n",
      "0.9911671\n",
      "0.99849665\n",
      "0.9996412\n",
      "0.9999622\n",
      "0\n",
      "0.23742223\n",
      "0.003293387\n",
      "0.8754655\n",
      "0.57514083\n",
      "0.9935074\n",
      "0.95978993\n",
      "0.9747853\n",
      "0.99640864\n",
      "7.93307e-07\n",
      "0\n",
      "0.9999275\n",
      "0.92217296\n",
      "0.95073867\n",
      "0.99934167\n",
      "0.9807451\n",
      "0.9707709\n",
      "0.9998386\n",
      "0.9948118\n",
      "0.9586091\n",
      "0\n",
      "0.79982555\n",
      "0.583894\n",
      "0.94326794\n",
      "0.95236456\n",
      "0.9736434\n",
      "0.9352516\n",
      "0.9804583\n",
      "0.0015958321\n",
      "0.0006459371\n",
      "0\n",
      "0.99810743\n",
      "0.99048424\n",
      "0.2397505\n",
      "0.2773027\n",
      "0.9911849\n",
      "0.82517105\n",
      "0.99239385\n",
      "0.999951\n",
      "0.3792833\n",
      "0\n",
      "0.7781152\n",
      "0.9753513\n",
      "0.99573565\n",
      "0.109053604\n",
      "0.45370647\n",
      "0.965152\n",
      "0.9920488\n",
      "0.9510558\n",
      "0.00052272103\n",
      "0\n",
      "0.9985569\n",
      "0.9893422\n",
      "0.9331983\n",
      "0.5317582\n",
      "0.10382272\n",
      "0.087675184\n",
      "0.9952467\n",
      "0.8694669\n",
      "0.99999833\n",
      "0\n",
      "0.35975313\n",
      "0.9891065\n",
      "0.9953251\n",
      "0.3545865\n",
      "0.9918996\n",
      "0.0019180953\n",
      "0.048144907\n",
      "0.9997756\n",
      "0.26587743\n",
      "0\n",
      "0.99979967\n",
      "0.99686265\n",
      "0.9961075\n",
      "0.99997807\n",
      "0.9996057\n",
      "0.98376596\n",
      "0.98628706\n",
      "0.97930306\n",
      "0.9999969\n",
      "0\n",
      "0.9992107\n",
      "0.721429\n",
      "0.99988973\n",
      "0.1349087\n",
      "0.9834975\n",
      "0.97448653\n",
      "0.9977063\n",
      "0.01002304\n",
      "0.9177894\n",
      "0\n",
      "0.9994937\n",
      "0.9983708\n",
      "0.9873546\n",
      "0.9168047\n",
      "0.99828315\n",
      "0.9964143\n",
      "0.9490972\n",
      "0.31862307\n",
      "0.9999988\n",
      "0\n",
      "0.9836278\n",
      "0.91697127\n",
      "0.0060864286\n",
      "0.8395716\n",
      "0.013049777\n",
      "0.99882513\n",
      "0.75444376\n",
      "0.79898393\n",
      "0.5448032\n",
      "0\n",
      "0.99977154\n",
      "0.9919487\n",
      "0.9993555\n",
      "0.99795616\n",
      "0.9995685\n",
      "0.056583066\n",
      "0.88284457\n",
      "0.9996049\n",
      "0.99996305\n",
      "0\n",
      "0.99912053\n",
      "0.99353117\n",
      "0.37041453\n",
      "0.9806935\n",
      "0.5194941\n",
      "0.63119173\n",
      "0.98322046\n",
      "0.07570478\n",
      "0.61646175\n",
      "0\n",
      "0.99977475\n",
      "0.991625\n",
      "0.55124474\n",
      "0.1437899\n",
      "0.0011540314\n",
      "0.9942524\n",
      "0.124477774\n",
      "0.99678\n",
      "0.9999994\n",
      "0\n",
      "0.99837506\n",
      "0.009568373\n",
      "0.46359897\n",
      "0.82326657\n",
      "0.99195284\n",
      "0.76230043\n",
      "0.9968911\n",
      "0.9951508\n",
      "0.66001785\n",
      "0\n",
      "0.9989691\n",
      "0.99777126\n",
      "0.9586951\n",
      "0.9994715\n",
      "0.23348084\n",
      "0.9815685\n",
      "0.8253204\n",
      "0.886791\n",
      "0.9975526\n",
      "0\n",
      "0.9989987\n",
      "0.9994586\n",
      "0.9985689\n",
      "0.40801495\n",
      "0.9821394\n",
      "0.90625256\n",
      "0.9988838\n",
      "0.91727877\n",
      "0.99976236\n",
      "0\n",
      "0.9997079\n",
      "0.99994266\n",
      "0.9995072\n",
      "0.9995677\n",
      "0.9836427\n",
      "0.99131763\n",
      "0.7197512\n",
      "0.9992052\n",
      "0.9999918\n",
      "0\n",
      "0.99988675\n",
      "0.94009525\n",
      "0.9238726\n",
      "0.99774456\n",
      "0.9888073\n",
      "0.91972697\n",
      "0.9976192\n",
      "0.854517\n",
      "0.9999893\n",
      "0\n",
      "0.9990308\n",
      "0.9995047\n",
      "0.9894163\n",
      "0.71059066\n",
      "0.26001835\n",
      "0.9998068\n",
      "0.9965113\n",
      "0.99150497\n",
      "0.99999774\n",
      "0\n",
      "0.9969907\n",
      "0.6406977\n",
      "0.0093925055\n",
      "0.8081923\n",
      "0.98261297\n",
      "0.15351495\n",
      "0.79405355\n",
      "0.99897397\n",
      "0.9986731\n",
      "0\n",
      "0.9997286\n",
      "0.994586\n",
      "0.9998417\n",
      "0.99913305\n",
      "0.99960274\n",
      "0.31935248\n",
      "0.49194697\n",
      "0.98261535\n",
      "0.99997103\n",
      "0\n",
      "0.9992107\n",
      "0.721429\n",
      "0.99988973\n",
      "0.1349087\n",
      "0.9834975\n",
      "0.97448653\n",
      "0.9977063\n",
      "0.01002304\n",
      "0.9177894\n",
      "0\n",
      "0.9994937\n",
      "0.9983708\n",
      "0.9873546\n",
      "0.9168047\n",
      "0.99828315\n",
      "0.9964143\n",
      "0.9490972\n",
      "0.31862307\n",
      "0.9999988\n",
      "0\n",
      "0.9836278\n",
      "0.91697127\n",
      "0.0060864286\n",
      "0.8395716\n",
      "0.013049777\n",
      "0.99882513\n",
      "0.75444376\n",
      "0.79898393\n",
      "0.5448032\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 23\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         perplexities\u001b[39m.\u001b[39mappend(Y_pred_prob \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mN))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmedian(perplexities)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m median_perplexity(model, encoded_sequences_val)\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X_sequence_embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[index_to_embedding[token_idx] \u001b[39mfor\u001b[39;00m token_idx \u001b[39min\u001b[39;00m X]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# get predictions - represented as softmax probabilities over the vocabulary \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m Y_prob_softmax \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_sequence_embeddings, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m N \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m Y_pred_log_prob \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2596\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2587\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2588\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2589\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2590\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2593\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2594\u001b[0m         )\n\u001b[1;32m-> 2596\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2597\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2598\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2599\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2600\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2601\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2602\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2603\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2604\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2605\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2606\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[0;32m   2607\u001b[0m )\n\u001b[0;32m   2609\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1293\u001b[0m     x,\n\u001b[0;32m   1294\u001b[0m     y,\n\u001b[0;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:314\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[0;32m    309\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[0;32m    316\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[0;32m    317\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \n\u001b[0;32m    319\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2268\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2264\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2267\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2268\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[0;32m   2269\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2270\u001b[0m     map_func,\n\u001b[0;32m   2271\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[0;32m   2272\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m   2273\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m    108\u001b[0m     map_func,\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    258\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    259\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    266\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1222\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1221\u001b[0m   \u001b[39m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1222\u001b[0m   concrete \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1223\u001b[0m   concrete\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1192\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1191\u001b[0m     initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 1192\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwargs, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m   1193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1195\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[0;32m   1196\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m   \u001b[39m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[0;32m    690\u001b[0m     variable_capturing_scope,\n\u001b[0;32m    691\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[0;32m    692\u001b[0m )\n\u001b[0;32m    693\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mtrace_function(\n\u001b[0;32m    695\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[0;32m    696\u001b[0m )\n\u001b[0;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    699\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[0;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[0;32m    180\u001b[0m   )\n\u001b[0;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:284\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    283\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[1;32m--> 284\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[0;32m    285\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[0;32m    286\u001b[0m )\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[0;32m    290\u001b[0m       concrete_function, current_func_context\n\u001b[0;32m    291\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:308\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[1;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m    304\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[0;32m    305\u001b[0m       placeholder_context\n\u001b[0;32m    306\u001b[0m   )\n\u001b[1;32m--> 308\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    309\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    310\u001b[0m     tracing_options\u001b[39m.\u001b[39;49mpython_function,\n\u001b[0;32m    311\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49margs,\n\u001b[0;32m    312\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39;49mkwargs,\n\u001b[0;32m    313\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    314\u001b[0m     func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    315\u001b[0m     arg_names\u001b[39m=\u001b[39;49mfunction_type_utils\u001b[39m.\u001b[39;49mto_arg_names(function_type),\n\u001b[0;32m    316\u001b[0m     create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    317\u001b[0m )\n\u001b[0;32m    319\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[0;32m    321\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1064\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n\u001b[1;32m-> 1064\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[0;32m   1065\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1067\u001b[0m \u001b[39m# flatten and unflatten func_args and func_kwargs to maintain parity\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m \u001b[39m# from flattening which sorts by key\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m func_args \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   1070\u001b[0m     func_args,\n\u001b[0;32m   1071\u001b[0m     nest\u001b[39m.\u001b[39mflatten(func_args, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   1072\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest.py:629\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    545\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \n\u001b[0;32m    547\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[0;32m    630\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    631\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1168\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m \n\u001b[0;32m   1073\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[1;32m-> 1168\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1169\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[0;32m   1170\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1208\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[0;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[1;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m entries],\n\u001b[0;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[0;32m   1210\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[0;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[1;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[0;32m   1210\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.convert\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1049\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo be compatible with tf.function, Python functions \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust return zero or more Tensors or ExtensionTypes or None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1051\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues; in compilation of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(python_func)\u001b[39m}\u001b[39;00m\u001b[39m, found return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1052\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, which is not a Tensor or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1053\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExtensionType.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1054\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m-> 1055\u001b[0m   x \u001b[39m=\u001b[39m deps_ctx\u001b[39m.\u001b[39;49mmark_as_return(x)\n\u001b[0;32m   1056\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:246\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.mark_as_return\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    241\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor_array_ops\u001b[39m.\u001b[39mbuild_ta_with_new_flow(tensor, flow)\n\u001b[0;32m    242\u001b[0m \u001b[39m# We want to make the return values depend on the stateful operations, but\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39m# we don't want to introduce a cycle, so we make the return value the result\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39m# of a new identity operation that the stateful operations definitely don't\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m# depend on.\u001b[39;00m\n\u001b[1;32m--> 246\u001b[0m tensor \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49midentity(tensor)\n\u001b[0;32m    247\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returned_tensors\u001b[39m.\u001b[39madd(tensor)\n\u001b[0;32m    248\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:321\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    318\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    319\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 321\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    322\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4988\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4986\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   4987\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 4988\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   4989\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   4990\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   4991\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    797\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2657\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   2654\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   2655\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   2656\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 2657\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39;49mfrom_node_def(\n\u001b[0;32m   2658\u001b[0m       node_def,\n\u001b[0;32m   2659\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2660\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   2661\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   2662\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   2663\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   2664\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   2665\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   2666\u001b[0m   )\n\u001b[0;32m   2667\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   2668\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1161\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   1160\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 1161\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   1162\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m   1163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:991\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m--> 991\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m    992\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m    993\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m    994\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m    995\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def median_perplexity(model, val_data: np.array):\n",
    "    padding_index = tokenizer.word_index.get(PADDING)\n",
    "    sentence_begin_index = tokenizer.word_index.get(SENTENCE_BEGIN)\n",
    "\n",
    "    perplexities = []\n",
    "    # iterate through each encoded validation sequence \n",
    "    for seq in val_data[:2000]: \n",
    "        # shift Y forward one token to represent the next word predictions \n",
    "        X = seq[:-1] \n",
    "        Y = seq[1:]\n",
    "\n",
    "        # get word embeddings for X as input to the model\n",
    "        X_sequence_embeddings = np.array([[index_to_embedding[token_idx] for token_idx in X]])\n",
    "\n",
    "        # get predictions - represented as softmax probabilities over the vocabulary \n",
    "        Y_prob_softmax = model.predict(X_sequence_embeddings, verbose=0)\n",
    "\n",
    "        N = 0\n",
    "        Y_pred_log_prob = 0\n",
    "        for i, y in enumerate(Y):\n",
    "            # 0 to get the only row in the batch, i to get the ith token prediction, y to get the predicted probability of the true value \n",
    "            y_pred_prob = Y_prob_softmax[0][i][y] \n",
    "            print(y_pred_prob)\n",
    "\n",
    "            Y_pred_log_prob += np.log(y_pred_prob)\n",
    "\n",
    "            # only include meaningful tokens in our token count \n",
    "            if y != padding_index and y != sentence_begin_index:\n",
    "                N += 1\n",
    "\n",
    "        Y_pred_prob = np.exp(Y_pred_log_prob)\n",
    "        perplexities.append(Y_pred_prob ** (-1/N))\n",
    "\n",
    "    return np.median(perplexities)\n",
    "\n",
    "median_perplexity(model, encoded_sequences_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.2886101, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3010134, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5138707, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14598623, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5041936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95334405, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54505557, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39290375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14598623, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5041936, shape=(), dtype=float32)\n",
      "tf.Tensor(1.188076, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27249914, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0948985, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3683962, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30174696, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6271188, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5041936, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5319726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5041936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42894843, shape=(), dtype=float32)\n",
      "tf.Tensor(1.298985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20974027, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15212175, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36819303, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81213856, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23046637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.60560614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029932095, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5375933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.86453795, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060784195, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31230652, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15507394, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54924613, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6371726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029932095, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1860253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.055232372, shape=(), dtype=float32)\n",
      "tf.Tensor(1.133155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027790666, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027790666, shape=(), dtype=float32)\n",
      "tf.Tensor(1.081153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29269314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20426454, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4317432, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1758337, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5828502, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39770415, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10671794, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7848908, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1447807, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2037139, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33427987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5796264, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2667474, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7018987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20375709, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12262049, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09830814, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4404047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.025445994, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6407961, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43338144, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2151589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6174103, shape=(), dtype=float32)\n",
      "tf.Tensor(1.410869, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0065279645, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7848908, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1447807, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2037139, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33427987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5796264, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2667474, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7018987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20375709, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12262049, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03957124, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04420823, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19033208, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82816297, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20839265, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7848908, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1447807, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2037139, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33427987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5745468, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2667474, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7018987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20375709, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12262049, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1705358, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4677495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.603656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1705358, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12262049, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1705358, shape=(), dtype=float32)\n",
      "tf.Tensor(0.603656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9503814, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7377937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7377937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.603656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2280645, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2280645, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08951618, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2943332, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48273623, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7722726, shape=(), dtype=float32)\n",
      "tf.Tensor(1.327054, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0964262, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4871382, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0304468, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1741296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6101184, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5294524, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8579147, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69369644, shape=(), dtype=float32)\n",
      "tf.Tensor(0.78583944, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47667012, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0964262, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5039478, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4438994, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0233736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32424974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.120682, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1560533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5111854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48582146, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2827779, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3152883, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8183968, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36219993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.854532, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68571234, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3570496, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51374364, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5047488, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47679743, shape=(), dtype=float32)\n",
      "tf.Tensor(0.072940044, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1380873, shape=(), dtype=float32)\n",
      "tf.Tensor(0.096135534, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7694528, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34555823, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6458905, shape=(), dtype=float32)\n",
      "tf.Tensor(0.017516198, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9194589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.438569, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4129775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10054132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9296024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.710771, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3326169, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1975915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49879578, shape=(), dtype=float32)\n",
      "tf.Tensor(0.046154514, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4285486, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5496097, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6374285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9194589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.438569, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4129775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10054132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9296024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36349708, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47396982, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61165583, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8682927, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61570317, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5275235, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0703155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9194589, shape=(), dtype=float32)\n",
      "tf.Tensor(0.438569, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4129775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10054132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9296024, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7283357, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4107121, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2294331, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6669416, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8903856, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9817524, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6459139, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5277944, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65735364, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2942293, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0403919, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8556061, shape=(), dtype=float32)\n",
      "tf.Tensor(0.033627335, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8737869, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3158817, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6827023, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5527276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026553173, shape=(), dtype=float32)\n",
      "tf.Tensor(0.99906605, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1309226, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7370936, shape=(), dtype=float32)\n",
      "tf.Tensor(1.44434, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3395591, shape=(), dtype=float32)\n",
      "tf.Tensor(0.60435325, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0309362, shape=(), dtype=float32)\n",
      "tf.Tensor(0.527381, shape=(), dtype=float32)\n",
      "tf.Tensor(0.173302, shape=(), dtype=float32)\n",
      "tf.Tensor(0.042103898, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06308038, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97932327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5787744, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03119925, shape=(), dtype=float32)\n",
      "tf.Tensor(0.017846575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0057747886, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6504029, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1544617, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11323828, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40136692, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7048364, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7676871, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02992424, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00814352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3596314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91184074, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54243445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.52187014, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0636326, shape=(), dtype=float32)\n",
      "tf.Tensor(0.020544803, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56872624, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25817868, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07898044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1754245, shape=(), dtype=float32)\n",
      "tf.Tensor(0.114215285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42663744, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07022599, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19692309, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16655329, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3368394, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58482885, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010991818, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0039477106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.045186106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10993922, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8764179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03551938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12435433, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25817868, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10993922, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8764179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03551938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12435433, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25817868, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25817868, shape=(), dtype=float32)\n",
      "tf.Tensor(0.948141, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2034788, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0487812, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91837335, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1896093, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5904495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48221076, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6513796, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6513796, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9080932, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2144308, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7353091, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9386389, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1896093, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2430202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48221076, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6513796, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8998517, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7832406, shape=(), dtype=float32)\n",
      "tf.Tensor(1.173058, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7410961, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31181848, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9204038, shape=(), dtype=float32)\n",
      "tf.Tensor(0.96369046, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1896093, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2430202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48221076, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6513796, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8998517, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5709955, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8783005, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1609076, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20709568, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4917799, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6257118, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1187961, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1022553, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8683524, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3110973, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8339784, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3014101, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4917799, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6257118, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1187961, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1022553, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5267153, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6648189, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1814816, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9327028, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02054291, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6291476, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6569256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9161065, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1522899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02054291, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47408664, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8160034, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49893638, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49273163, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6937119, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48636878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70649207, shape=(), dtype=float32)\n",
      "tf.Tensor(0.63641644, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81112003, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8922949, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21224195, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1088276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67432135, shape=(), dtype=float32)\n",
      "tf.Tensor(0.87401116, shape=(), dtype=float32)\n",
      "tf.Tensor(0.77485347, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6962882, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47623333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6880799, shape=(), dtype=float32)\n",
      "tf.Tensor(0.87225556, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45103577, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1918799, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1853474, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31596065, shape=(), dtype=float32)\n",
      "tf.Tensor(1.011132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5456964, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8265607, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21540226, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4586304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0063865357, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2479658, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33249247, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2197468, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1516929, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15823625, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(1.088602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0071805236, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2759781, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22300965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(1.20531, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3563502, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81613326, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2328345, shape=(), dtype=float32)\n",
      "tf.Tensor(0.006740185, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6959595, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5690144, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(1.20531, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3563502, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81613326, shape=(), dtype=float32)\n",
      "tf.Tensor(2.456069, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2339256, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0113149, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0279785, shape=(), dtype=float32)\n",
      "tf.Tensor(3.7572522, shape=(), dtype=float32)\n",
      "tf.Tensor(3.2457874, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9754777, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11072199, shape=(), dtype=float32)\n",
      "tf.Tensor(0.72823614, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4828905, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9879061, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02907816, shape=(), dtype=float32)\n",
      "tf.Tensor(1.260772, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6601987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59512305, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3624606, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1508899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5647438, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7612841, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70153874, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7869573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9308511, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2884222, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8332876, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5349047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46133375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18702115, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8199855, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37512612, shape=(), dtype=float32)\n",
      "tf.Tensor(2.867277, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9758479, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7869573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9308511, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2884222, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2201939, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1986605, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8137901, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009641708, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7869573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9308511, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2884222, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7869573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2884222, shape=(), dtype=float32)\n",
      "tf.Tensor(1.829255, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5604565, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41396075, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3676624, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9960213, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0077146, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6516921, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0942522, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7368619, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5303237, shape=(), dtype=float32)\n",
      "tf.Tensor(0.72481525, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7425933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5556296, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3578643, shape=(), dtype=float32)\n",
      "tf.Tensor(1.361803, shape=(), dtype=float32)\n",
      "tf.Tensor(0.909215, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7781119, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8381932, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7062976, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3173552, shape=(), dtype=float32)\n",
      "tf.Tensor(0.909215, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.909215, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8458775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6531197, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8755917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.84944165, shape=(), dtype=float32)\n",
      "tf.Tensor(0.909215, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95482975, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0617006, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1866757, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6972367, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5865091, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6706157, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2861862, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0511317, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59995425, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29344052, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2176722, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9084752, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29344052, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9250636, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4722432, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6773301, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0688673, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0974045, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68495995, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4220186, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6814672, shape=(), dtype=float32)\n",
      "tf.Tensor(0.025911797, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20475455, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06883187, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44732392, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03479138, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06944391, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.089108825, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14636923, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16124502, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0750806, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4890175, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34930518, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23139967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6331227, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0105386, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0252967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7822273, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6451322, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5643202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0105386, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14185174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01228532, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07516277, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08243316, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2864702, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8760657, shape=(), dtype=float32)\n",
      "tf.Tensor(0.84607065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19431464, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011446042, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07155668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48585, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5643202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0105386, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17861417, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008195628, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1665716, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6269377, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2373766, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5015873, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004400197, shape=(), dtype=float32)\n",
      "tf.Tensor(0.58558875, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4620652, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1894525, shape=(), dtype=float32)\n",
      "tf.Tensor(0.082875535, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44562632, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2350764, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6972599, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03166135, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9583898, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20044754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8644787, shape=(), dtype=float32)\n",
      "tf.Tensor(1.987257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004448633, shape=(), dtype=float32)\n",
      "tf.Tensor(0.071127966, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2003356, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0082276, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3237616, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6526822, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0701256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9517033, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3961002, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1695447, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9495734, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8220348, shape=(), dtype=float32)\n",
      "tf.Tensor(1.987257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75654376, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1051652, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5239336, shape=(), dtype=float32)\n",
      "tf.Tensor(0.739503, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75654376, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0734917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85575014, shape=(), dtype=float32)\n",
      "tf.Tensor(1.360053, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75654376, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3075881, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9545663, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9835366, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5931747, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2913122, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48890474, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75654376, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75654376, shape=(), dtype=float32)\n",
      "tf.Tensor(1.093683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46067885, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09024319, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3653704, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1623833, shape=(), dtype=float32)\n",
      "tf.Tensor(0.031761363, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1520929, shape=(), dtype=float32)\n",
      "tf.Tensor(0.598587, shape=(), dtype=float32)\n",
      "tf.Tensor(2.02338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08041913, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18330643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.028040491, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32574072, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1405654, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07818873, shape=(), dtype=float32)\n",
      "tf.Tensor(0.824243, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92974675, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4036818, shape=(), dtype=float32)\n",
      "tf.Tensor(0.598587, shape=(), dtype=float32)\n",
      "tf.Tensor(2.02338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08041913, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18330643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.028040491, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3484401, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16511518, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012619171, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.598587, shape=(), dtype=float32)\n",
      "tf.Tensor(2.02338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08041913, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18330643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.028040491, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02882519, shape=(), dtype=float32)\n",
      "tf.Tensor(0.037198815, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1298704, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1760387, shape=(), dtype=float32)\n",
      "tf.Tensor(0.76315314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97589236, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9355974, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53862745, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1045105, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2721562, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6981854, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6552846, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011949448, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8059237, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3574579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9857972, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1300147, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9097228, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3638988, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8418808, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9355974, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6552846, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011949448, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8059237, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3574579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9857972, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1300147, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8496824, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82170826, shape=(), dtype=float32)\n",
      "tf.Tensor(1.14555, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9375918, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1760387, shape=(), dtype=float32)\n",
      "tf.Tensor(0.76315314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97589236, shape=(), dtype=float32)\n",
      "tf.Tensor(2.6552846, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011949448, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8059237, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3574579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.62038064, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06452016, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1300147, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1006763, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4240855, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2748222, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35213, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43365166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3188405, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14263816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03466801, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20687029, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16326481, shape=(), dtype=float32)\n",
      "tf.Tensor(0.033639368, shape=(), dtype=float32)\n",
      "tf.Tensor(0.092312545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09229313, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12899145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.095387235, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09438967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08691975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06414962, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03807038, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43432504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47051376, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03639233, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2966744, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36512187, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49971682, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17409566, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6176708, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18352896, shape=(), dtype=float32)\n",
      "tf.Tensor(0.333771, shape=(), dtype=float32)\n",
      "tf.Tensor(0.022938257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4573512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82330066, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16326481, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16326481, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019163556, shape=(), dtype=float32)\n",
      "tf.Tensor(0.092312545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09229313, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12899145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.095387235, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17345798, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08691975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17000256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3082381, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4474753, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6991007, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7431781, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8876792, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28882632, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2602499, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5295398, shape=(), dtype=float32)\n",
      "tf.Tensor(0.020675493, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47940385, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4098331, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19846576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27267888, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1012032, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9288826, shape=(), dtype=float32)\n",
      "tf.Tensor(0.017393304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32786638, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0042587738, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214603, shape=(), dtype=float32)\n",
      "tf.Tensor(0.052003156, shape=(), dtype=float32)\n",
      "tf.Tensor(0.484018, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28882632, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2602499, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5295398, shape=(), dtype=float32)\n",
      "tf.Tensor(0.020675493, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47940385, shape=(), dtype=float32)\n",
      "tf.Tensor(1.177052, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19846576, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9832163, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1161559, shape=(), dtype=float32)\n",
      "tf.Tensor(2.9478292, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0981574, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4773288, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1840613, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50715584, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214874, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2107451, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34927282, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029924717, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018061407, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27506247, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40677825, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214874, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59073997, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6326909, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9348967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40807834, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003465044, shape=(), dtype=float32)\n",
      "tf.Tensor(1.490193, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09185719, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214874, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1620954, shape=(), dtype=float32)\n",
      "tf.Tensor(0.73373413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.62845963, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56275314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.066237494, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6605899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36113924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214874, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2107451, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34927282, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12595174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018061407, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27506247, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5824187, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3214874, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4836984, shape=(), dtype=float32)\n",
      "tf.Tensor(1.110704, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7285696, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1551111, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027989127, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1970339, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8359596, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1654775, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2023236, shape=(), dtype=float32)\n",
      "tf.Tensor(2.415124, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95742947, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9238312, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1277279, shape=(), dtype=float32)\n",
      "tf.Tensor(2.24448, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5324955, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3458207, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9872945, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20508891, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8359596, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1654775, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2023236, shape=(), dtype=float32)\n",
      "tf.Tensor(2.415124, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95742947, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9238312, shape=(), dtype=float32)\n",
      "tf.Tensor(3.1519334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.94418824, shape=(), dtype=float32)\n",
      "tf.Tensor(2.300542, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9468108, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9498266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.72407395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4739792, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65623105, shape=(), dtype=float32)\n",
      "tf.Tensor(0.073366255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9238312, shape=(), dtype=float32)\n",
      "tf.Tensor(1.030147, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7687449, shape=(), dtype=float32)\n",
      "tf.Tensor(2.088708, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2754025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.039732203, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0239983, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0488493, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5182445, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1370307, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8843037, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5039308, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8843037, shape=(), dtype=float32)\n",
      "tf.Tensor(1.134468, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3780735, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6257192, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3070929, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20673564, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2298087, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1370307, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8843037, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5039308, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8843037, shape=(), dtype=float32)\n",
      "tf.Tensor(1.134468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.039732203, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0239983, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0488493, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0161452, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1370307, shape=(), dtype=float32)\n",
      "tf.Tensor(0.249753, shape=(), dtype=float32)\n",
      "tf.Tensor(1.596101, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8843037, shape=(), dtype=float32)\n",
      "tf.Tensor(1.134468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.065379776, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50990325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50990325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50990325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50990325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.84672165, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7178891, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19328083, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0543878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026491268, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54822814, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29478428, shape=(), dtype=float32)\n",
      "tf.Tensor(0.114833765, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2424132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37999025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027228333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41856858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04747736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16640492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0110985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5201592, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10433242, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5756163, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2894533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37999025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027228333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41856858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04747736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16640492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0110985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37999025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027228333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41856858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04747736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16640492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0110985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37999025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.027228333, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41856858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04747736, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16640492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027489334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80854464, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9121933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6070601, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6849243, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35915807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29539585, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5895721, shape=(), dtype=float32)\n",
      "tf.Tensor(0.235166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6304284, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35929132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025506695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07056579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36730188, shape=(), dtype=float32)\n",
      "tf.Tensor(0.89872956, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41503337, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14499018, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20195267, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5895721, shape=(), dtype=float32)\n",
      "tf.Tensor(0.235166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6304284, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35929132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025506695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6574015, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04406064, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35929132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025506695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0032388014, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80854464, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9121933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025506695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8404915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35915807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025506695, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28883567, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3332568, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59943295, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30091172, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0307546, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67479587, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13868374, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0555948, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07038637, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0939758, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13686796, shape=(), dtype=float32)\n",
      "tf.Tensor(0.05651658, shape=(), dtype=float32)\n",
      "tf.Tensor(0.71377397, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49566227, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026488848, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13371661, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25822672, shape=(), dtype=float32)\n",
      "tf.Tensor(0.036951583, shape=(), dtype=float32)\n",
      "tf.Tensor(0.89337665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7502444, shape=(), dtype=float32)\n",
      "tf.Tensor(0.037970837, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10776194, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2890552, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17312804, shape=(), dtype=float32)\n",
      "tf.Tensor(0.616693, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4004637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22870938, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22803126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.086633936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6730932, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61038846, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4011488, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2871766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.039136942, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2193495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39227608, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2070117, shape=(), dtype=float32)\n",
      "tf.Tensor(0.030108001, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1368737, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9135812, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09220322, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02142648, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7433162, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69724685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22485307, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012911206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24405538, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6376422, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12816219, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23986976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97618836, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27284423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.044932082, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1353971, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42383257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48111746, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7977884, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09220322, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02142648, shape=(), dtype=float32)\n",
      "tf.Tensor(1.258433, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69724685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09220322, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02142648, shape=(), dtype=float32)\n",
      "tf.Tensor(1.258433, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11295734, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026343426, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44077194, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21788488, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44170773, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16854495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4327679, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67332304, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1687077, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53062576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060350716, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0350327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2069226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40722793, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0889996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3769976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.76924586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9715004, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06579189, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53273576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.014390562, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1643614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70045114, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91876805, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1546435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.098716155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4920534, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1307042, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9317451, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30533275, shape=(), dtype=float32)\n",
      "tf.Tensor(0.086427316, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27371195, shape=(), dtype=float32)\n",
      "tf.Tensor(0.76924586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5201968, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18530709, shape=(), dtype=float32)\n",
      "tf.Tensor(0.62418735, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56016815, shape=(), dtype=float32)\n",
      "tf.Tensor(1.286902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4936838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4323614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31334254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6928169, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13588886, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70196617, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26558053, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0038607316, shape=(), dtype=float32)\n",
      "tf.Tensor(0.034798734, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4936838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8938697, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31334254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(0.702811, shape=(), dtype=float32)\n",
      "tf.Tensor(0.60617405, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4558887, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42267492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45750487, shape=(), dtype=float32)\n",
      "tf.Tensor(1.035852, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07086769, shape=(), dtype=float32)\n",
      "tf.Tensor(2.049032, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55490285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.109003484, shape=(), dtype=float32)\n",
      "tf.Tensor(0.109706335, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6239928, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4253128, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20707329, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9406136, shape=(), dtype=float32)\n",
      "tf.Tensor(0.52170414, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0024085892, shape=(), dtype=float32)\n",
      "tf.Tensor(1.286902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4936838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46936586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36521423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(0.093016915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21971488, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5002095, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3480791, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0065325317, shape=(), dtype=float32)\n",
      "tf.Tensor(1.286902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4936838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46936586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36521423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91667813, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1011901, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3110986, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1158047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37474716, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39107338, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2127088, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5983218, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37474716, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3574535, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8845372, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4458134, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24953479, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8755019, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56118155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7890476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8687936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53085506, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80409896, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5476766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.548675, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2985399, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6966624, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3388101, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8430574, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2135987, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3574535, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8845372, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4458134, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24953479, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8755019, shape=(), dtype=float32)\n",
      "tf.Tensor(0.56118155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7890476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8687936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53085506, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80409896, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5476766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.548675, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2985399, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4194638, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7982451, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32529008, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4941667, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5315345, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0851315, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40674347, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19273992, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8755019, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80409896, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5476766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.016450558, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61989075, shape=(), dtype=float32)\n",
      "tf.Tensor(1.651354, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65039665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65039665, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0392106, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1612389, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0138365, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37474716, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27745697, shape=(), dtype=float32)\n",
      "tf.Tensor(0.116954155, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4377697, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4045991, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4742991, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18137676, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3110537, shape=(), dtype=float32)\n",
      "tf.Tensor(0.051163986, shape=(), dtype=float32)\n",
      "tf.Tensor(0.051163986, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004042778, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10672242, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4062567, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9616878, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5183692, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4265075, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1578312, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7875675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7875675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004042778, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0419798, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8344344, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6458865, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13877788, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39905727, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6433728, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1423566, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7875675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7875675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54338044, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8742343, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0359492, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2392138, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97787786, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1772543, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6182822, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2399749, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6372069, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85686755, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4193892, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44977167, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55479777, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7798076, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6871219, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0680234, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6182822, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2399749, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6372069, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85686755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9614013, shape=(), dtype=float32)\n",
      "tf.Tensor(2.00794, shape=(), dtype=float32)\n",
      "tf.Tensor(0.85669774, shape=(), dtype=float32)\n",
      "tf.Tensor(1.18657, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9472945, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4302563, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4302563, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43713912, shape=(), dtype=float32)\n",
      "tf.Tensor(0.044176705, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7286269, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08835122, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010960467, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09451669, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44577852, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013197973, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2540208, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69560957, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09367153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008297178, shape=(), dtype=float32)\n",
      "tf.Tensor(0.90365994, shape=(), dtype=float32)\n",
      "tf.Tensor(0.056045268, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95302975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06430314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013957348, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4598533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.061177194, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39664543, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34466305, shape=(), dtype=float32)\n",
      "tf.Tensor(0.552716, shape=(), dtype=float32)\n",
      "tf.Tensor(0.022229113, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12138002, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2540208, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69560957, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09367153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008297178, shape=(), dtype=float32)\n",
      "tf.Tensor(0.90365994, shape=(), dtype=float32)\n",
      "tf.Tensor(0.056045268, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95302975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.33386973, shape=(), dtype=float32)\n",
      "tf.Tensor(0.77623105, shape=(), dtype=float32)\n",
      "tf.Tensor(0.699456, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029213468, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08171056, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32077965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39559236, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29504353, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69560957, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09367153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008297178, shape=(), dtype=float32)\n",
      "tf.Tensor(0.57636833, shape=(), dtype=float32)\n",
      "tf.Tensor(0.056045268, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95302975, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06430314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11286916, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06430314, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023601841, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01795549, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29198992, shape=(), dtype=float32)\n",
      "tf.Tensor(3.5634809, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1308829, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45518863, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060758658, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3342894, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4615369, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060758658, shape=(), dtype=float32)\n",
      "tf.Tensor(0.53147006, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7243858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67092854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03935106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060758658, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3342894, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5131109, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03935106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.060758658, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3342894, shape=(), dtype=float32)\n",
      "tf.Tensor(0.80810577, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03935106, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8728871, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0147699, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5988071, shape=(), dtype=float32)\n",
      "tf.Tensor(3.602879, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6666592, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2601115, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0017282825, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12409809, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30915838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75284505, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019936712, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0905576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20385215, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010670075, shape=(), dtype=float32)\n",
      "tf.Tensor(2.2967153, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20136969, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5578013, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06286906, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3639703, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4866295, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55855113, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0064027, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8566392, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9511172, shape=(), dtype=float32)\n",
      "tf.Tensor(0.699944, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5041936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55565995, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6826776, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5617603, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1015505, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9296396, shape=(), dtype=float32)\n",
      "tf.Tensor(1.512261, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32509506, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2913865, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0576382, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48736605, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1944845, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0604044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42444226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6588683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27141166, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3788373, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9192579, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2990878, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7642877, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1293954, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0604044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42444226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6588683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27141166, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1497035, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0604044, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42444226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59747726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27141166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008040361, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3341807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27141166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.021153506, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1185313, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8548017, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8209177, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0294993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.86603254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31858152, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21661103, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8128866, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19731982, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026835687, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21175717, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02932631, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09548533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5794757, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8159269, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023389628, shape=(), dtype=float32)\n",
      "tf.Tensor(0.47156674, shape=(), dtype=float32)\n",
      "tf.Tensor(0.100603, shape=(), dtype=float32)\n",
      "tf.Tensor(1.650702, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7540879, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92452174, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1814618, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3457886, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0258446, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5489566, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0188779, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0972476, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7117149, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9101751, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5174754, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8363035, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3665832, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6004499, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7775965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92814296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5022708, shape=(), dtype=float32)\n",
      "tf.Tensor(1.078145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92814296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7243302, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6880014, shape=(), dtype=float32)\n",
      "tf.Tensor(2.118195, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4172266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6603208, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92814296, shape=(), dtype=float32)\n",
      "tf.Tensor(1.155491, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5625411, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92814296, shape=(), dtype=float32)\n",
      "tf.Tensor(3.435471, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9366455, shape=(), dtype=float32)\n",
      "tf.Tensor(0.92814296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13434947, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8075144, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55952907, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18245816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003959771, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8046782, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38393533, shape=(), dtype=float32)\n",
      "tf.Tensor(1.9962395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12397505, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0935783, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2365179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.398503, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0970284, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8075144, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55952907, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18245816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003959771, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6354549, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15546584, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25392348, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8367755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43755758, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1740958, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8075144, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55952907, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18245816, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003959771, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1711413, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25425202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09316869, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029224852, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16789733, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7850291, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37422222, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2954669, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4339175, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07875371, shape=(), dtype=float32)\n",
      "tf.Tensor(1.592035, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0988765, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004431708, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9974059, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9974059, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013127002, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4476319, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3416181, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6776338, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46623543, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2569446, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1724734, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2701527, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55389667, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2780396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.029372849, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09043375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55777496, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1638255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10300793, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38405755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21122977, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0085867755, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5483177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.025627302, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13674062, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7188663, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6159064, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67988056, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020428733, shape=(), dtype=float32)\n",
      "tf.Tensor(0.005590206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020428733, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.83590394, shape=(), dtype=float32)\n",
      "tf.Tensor(0.068061665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011286426, shape=(), dtype=float32)\n",
      "tf.Tensor(0.023069764, shape=(), dtype=float32)\n",
      "tf.Tensor(0.88446933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01386433, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019355228, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97203094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3732858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.81657296, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5899055, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02426074, shape=(), dtype=float32)\n",
      "tf.Tensor(0.87841296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16770142, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6370183, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21930641, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23116387, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17638966, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3051612, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19053863, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0885805, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.04987789, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36488146, shape=(), dtype=float32)\n",
      "tf.Tensor(1.599013, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8020166, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1024487, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0036498855, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8303072, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35970068, shape=(), dtype=float32)\n",
      "tf.Tensor(0.43589905, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011578773, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5670936, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8462354, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7428832, shape=(), dtype=float32)\n",
      "tf.Tensor(1.127674, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49266917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.018811855, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5023047, shape=(), dtype=float32)\n",
      "tf.Tensor(3.9150438, shape=(), dtype=float32)\n",
      "tf.Tensor(0.46167073, shape=(), dtype=float32)\n",
      "tf.Tensor(2.5421987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.83590394, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1181102, shape=(), dtype=float32)\n",
      "tf.Tensor(1.229834, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27970782, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2325935, shape=(), dtype=float32)\n",
      "tf.Tensor(0.50775933, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2405342, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7936804, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1224527, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.90262765, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25815478, shape=(), dtype=float32)\n",
      "tf.Tensor(0.87407136, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011578773, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7577273, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17554767, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38444468, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5557449, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3303162, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19730976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5524258, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25921902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1614285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2482214, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011734623, shape=(), dtype=float32)\n",
      "tf.Tensor(2.461532, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30859283, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5986807, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3216996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.87284327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28610766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10175588, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7743944, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5797719, shape=(), dtype=float32)\n",
      "tf.Tensor(0.79775095, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1781859, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7757005, shape=(), dtype=float32)\n",
      "tf.Tensor(0.39798513, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1028174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25921902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1614285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.038195327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009914103, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4089618, shape=(), dtype=float32)\n",
      "tf.Tensor(0.1357194, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6697421, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6610609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23078857, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64319396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41541547, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95646656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.015065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11449557, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9369565, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11316751, shape=(), dtype=float32)\n",
      "tf.Tensor(0.036785953, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7148867, shape=(), dtype=float32)\n",
      "tf.Tensor(0.02603131, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17004693, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0494026, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1840694, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32636255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6697421, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6610609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23078857, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64319396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41541547, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95646656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.015065, shape=(), dtype=float32)\n",
      "tf.Tensor(1.125536, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3190174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8108052, shape=(), dtype=float32)\n",
      "tf.Tensor(1.109251, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0857388, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06929746, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6225721, shape=(), dtype=float32)\n",
      "tf.Tensor(1.6610609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.23078857, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64319396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41541547, shape=(), dtype=float32)\n",
      "tf.Tensor(0.95646656, shape=(), dtype=float32)\n",
      "tf.Tensor(1.015065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7148867, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16403271, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22536622, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9942466, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06370103, shape=(), dtype=float32)\n",
      "tf.Tensor(0.89141285, shape=(), dtype=float32)\n",
      "tf.Tensor(0.70377094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07271682, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016766083, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7882241, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13982518, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32957852, shape=(), dtype=float32)\n",
      "tf.Tensor(0.31567937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38545138, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1852916, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5945609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.7778937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.30831516, shape=(), dtype=float32)\n",
      "tf.Tensor(1.510334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24141404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82855123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26190177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07078278, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2412254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75517976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24141404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8188503, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27635652, shape=(), dtype=float32)\n",
      "tf.Tensor(0.16976912, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009398871, shape=(), dtype=float32)\n",
      "tf.Tensor(0.20016126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.73744243, shape=(), dtype=float32)\n",
      "tf.Tensor(0.14391592, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8992425, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011372979, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24141404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.82855123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.26190177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07078278, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2412254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75517976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24141404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8188503, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2412254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.75517976, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24141404, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8188503, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24671692, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3484796, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03943731, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24058434, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12169906, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0470603, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29746065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.34803796, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4308654, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1723807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8838094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44926983, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29822224, shape=(), dtype=float32)\n",
      "tf.Tensor(0.90606856, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67101073, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27727842, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0464149, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41542202, shape=(), dtype=float32)\n",
      "tf.Tensor(0.37684932, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07193598, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4308654, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1723807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8838094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44926983, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2956585, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1723807, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8838094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44926983, shape=(), dtype=float32)\n",
      "tf.Tensor(0.12406576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07516051, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8507685, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0894331, shape=(), dtype=float32)\n",
      "tf.Tensor(0.71403426, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7860053, shape=(), dtype=float32)\n",
      "tf.Tensor(0.74391985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9594969, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2774574, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7517962, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4366134, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1158097, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41098538, shape=(), dtype=float32)\n",
      "tf.Tensor(0.526365, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64613014, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8837261, shape=(), dtype=float32)\n",
      "tf.Tensor(2.7190437, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5331118, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8537476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2720438, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29537925, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2720438, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3277245, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29537925, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2720438, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.3132854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.18356998, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.64649695, shape=(), dtype=float32)\n",
      "tf.Tensor(1.5114198, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3277245, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68734616, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2720438, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67445445, shape=(), dtype=float32)\n",
      "tf.Tensor(0.36642087, shape=(), dtype=float32)\n",
      "tf.Tensor(1.090366, shape=(), dtype=float32)\n",
      "tf.Tensor(0.09535427, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27403188, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5186784, shape=(), dtype=float32)\n",
      "tf.Tensor(0.44860405, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27435172, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15085019, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06610525, shape=(), dtype=float32)\n",
      "tf.Tensor(0.692794, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45157993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009550263, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3270899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5800388, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08925375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.068265334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97503483, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3407441, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35348418, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8779561, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28113693, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2344241, shape=(), dtype=float32)\n",
      "tf.Tensor(0.48066515, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019508857, shape=(), dtype=float32)\n",
      "tf.Tensor(0.59807926, shape=(), dtype=float32)\n",
      "tf.Tensor(0.961147, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4849383, shape=(), dtype=float32)\n",
      "tf.Tensor(0.026986916, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45157993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009550263, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3270899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5800388, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08925375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.068265334, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97503483, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3407441, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06810602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.61926264, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13241725, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21375084, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45157993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.41494504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97503483, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3407441, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97503483, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3407441, shape=(), dtype=float32)\n",
      "tf.Tensor(1.4426174, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0335243, shape=(), dtype=float32)\n",
      "tf.Tensor(1.7975396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49423206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5811684, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27242598, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68859285, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8739514, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6516685, shape=(), dtype=float32)\n",
      "tf.Tensor(2.3984709, shape=(), dtype=float32)\n",
      "tf.Tensor(0.78486145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.25434148, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5811684, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27242598, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68859285, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8739514, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28087232, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0183271, shape=(), dtype=float32)\n",
      "tf.Tensor(0.28632855, shape=(), dtype=float32)\n",
      "tf.Tensor(2.1254835, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0334486, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5811684, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27242598, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68859285, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8739514, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5811684, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27242598, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68859285, shape=(), dtype=float32)\n",
      "tf.Tensor(1.8739514, shape=(), dtype=float32)\n",
      "tf.Tensor(0.621906, shape=(), dtype=float32)\n",
      "tf.Tensor(0.54052347, shape=(), dtype=float32)\n",
      "tf.Tensor(0.030621357, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0669772, shape=(), dtype=float32)\n",
      "tf.Tensor(0.036173724, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2937614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.354221, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07925883, shape=(), dtype=float32)\n",
      "tf.Tensor(0.10917513, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8792741, shape=(), dtype=float32)\n",
      "tf.Tensor(0.024851814, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         perplexities\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39me \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m prob)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmedian(perplexities)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m median_perplexity2(model, encoded_sequences_val)\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m Y_hot \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_categorical(y, num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(index_to_embedding)) \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m Y])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# get predictions - represented as softmax probabilities over the vocabulary \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m Y_prob_softmax \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_sequence_embeddings, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ce \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m prob \u001b[39m=\u001b[39m ce(Y_hot, Y_prob_softmax)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2596\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2587\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2588\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2589\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2590\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2593\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2594\u001b[0m         )\n\u001b[1;32m-> 2596\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2597\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2598\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2599\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2600\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2601\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2602\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2603\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2604\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2605\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2606\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[0;32m   2607\u001b[0m )\n\u001b[0;32m   2609\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2610\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1688\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1687\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1688\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1292\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1291\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1292\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1293\u001b[0m     x,\n\u001b[0;32m   1294\u001b[0m     y,\n\u001b[0;32m   1295\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1296\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1297\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1298\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1299\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1300\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1301\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1302\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1303\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1304\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1305\u001b[0m     pss_evaluation_shards\u001b[39m=\u001b[39;49mpss_evaluation_shards,\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1308\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:370\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m options\u001b[39m.\u001b[39mexperimental_distribute\u001b[39m.\u001b[39mauto_shard_policy \u001b[39m=\u001b[39m (\n\u001b[0;32m    366\u001b[0m     tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mAutoShardPolicy\u001b[39m.\u001b[39mDATA\n\u001b[0;32m    367\u001b[0m )\n\u001b[0;32m    368\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mwith_options(options)\n\u001b[1;32m--> 370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mprefetch(tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mAUTOTUNE)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1234\u001b[0m, in \u001b[0;36mDatasetV2.prefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprefetch\u001b[39m(\u001b[39mself\u001b[39m, buffer_size, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1207\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a `Dataset` that prefetches elements from this dataset.\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \n\u001b[0;32m   1209\u001b[0m \u001b[39m  Most dataset input pipelines should end with a call to `prefetch`. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1232\u001b[0m \u001b[39m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1234\u001b[0m   \u001b[39mreturn\u001b[39;00m prefetch_op\u001b[39m.\u001b[39;49m_prefetch(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m   1235\u001b[0m       \u001b[39mself\u001b[39;49m, buffer_size, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:28\u001b[0m, in \u001b[0;36m_prefetch\u001b[1;34m(input_dataset, buffer_size, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mif\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     27\u001b[0m   \u001b[39mreturn\u001b[39;00m input_dataset\n\u001b[1;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m _PrefetchDataset(input_dataset, buffer_size, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\prefetch_op.py:46\u001b[0m, in \u001b[0;36m_PrefetchDataset.__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m# We colocate the prefetch dataset with its input as this collocation only\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# happens automatically in graph mode.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(input_dataset\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m---> 46\u001b[0m   variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mprefetch_dataset(\n\u001b[0;32m     47\u001b[0m       input_dataset\u001b[39m.\u001b[39;49m_variant_tensor,\n\u001b[0;32m     48\u001b[0m       buffer_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_size,\n\u001b[0;32m     49\u001b[0m       slack_period\u001b[39m=\u001b[39;49mslack_period,\n\u001b[0;32m     50\u001b[0m       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_common_args)\n\u001b[0;32m     51\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6094\u001b[0m, in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   6092\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   6093\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 6094\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   6095\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mPrefetchDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, input_dataset, buffer_size,\n\u001b[0;32m   6096\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39moutput_types\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_types, \u001b[39m\"\u001b[39;49m\u001b[39moutput_shapes\u001b[39;49m\u001b[39m\"\u001b[39;49m, output_shapes,\n\u001b[0;32m   6097\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mslack_period\u001b[39;49m\u001b[39m\"\u001b[39;49m, slack_period, \u001b[39m\"\u001b[39;49m\u001b[39mlegacy_autotune\u001b[39;49m\u001b[39m\"\u001b[39;49m, legacy_autotune,\n\u001b[0;32m   6098\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mbuffer_size_min\u001b[39;49m\u001b[39m\"\u001b[39;49m, buffer_size_min, \u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m, metadata)\n\u001b[0;32m   6099\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   6100\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# e ** cross entropy loss\n",
    "def median_perplexity2(model, val_data: np.array):\n",
    "    padding_index = tokenizer.word_index.get(PADDING)\n",
    "    sentence_begin_index = tokenizer.word_index.get(SENTENCE_BEGIN)\n",
    "\n",
    "    perplexities = []\n",
    "    # iterate through each encoded validation sequence \n",
    "    for seq in val_data[:2000]: \n",
    "        # shift Y forward one token to represent the next word predictions \n",
    "        X = seq[:-1] \n",
    "        Y = seq[1:]\n",
    "\n",
    "        # get word embeddings for X as input to the model\n",
    "        X_sequence_embeddings = np.array([[index_to_embedding[token_idx] for token_idx in X]])\n",
    "        Y_hot = np.array([to_categorical(y, num_classes=len(index_to_embedding)) for y in Y])\n",
    "        # get predictions - represented as softmax probabilities over the vocabulary \n",
    "        Y_prob_softmax = model.predict(X_sequence_embeddings, verbose=0)[0]\n",
    "    \n",
    "        ce = keras.losses.CategoricalCrossentropy()\n",
    "        prob = ce(Y_hot, Y_prob_softmax)\n",
    "        print(prob)\n",
    "        perplexities.append(np.e ** prob)\n",
    "\n",
    "    return np.median(perplexities)\n",
    "\n",
    "median_perplexity2(model, encoded_sequences_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sequence length -- start with a small value -> increase to 12 and see how it impacts output\n",
    "# experiment with different embedding sizes --> maybe 100, 200\n",
    "# hidden units -- start 128, increase to 1000 \n",
    "# keep track of accuracy graph \n",
    "\n",
    "\n",
    "# ideas\n",
    "# concat \n",
    "# by line \n",
    "# embedding size 100, 200 hidden units, sequence length 10, 20 epochs -- standard \n",
    "# embedding size 200, 200 hidden units, sequence length 10, 20 epochs -- larger embedding \n",
    "# embedding size 100, 500 hidden units, sequence length 10, 20 epochs -- more hidden units\n",
    "# embedding size 100, 200 hidden units, sequence length 5, 20 epochs -- smaller sequence length \n",
    "# embedding size 100, 200 hidden units, sequence length 15, 20 epochs -- larger sequence length \n",
    "# embedding size 200, 200 hidden units, sequence length 10, 40 epochs -- more epochs \n",
    "\n",
    "# by verse \n",
    "# embedding size 100, 200 hidden units, sequence length 10, 20 epochs -- standard \n",
    "# embedding size 100, 200 hidden units, sequence length 15, 20 epochs -- larger sequence length "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with Hyperparameters \n",
    "\n",
    "To find our final configuration for our RNN + LSTM model, we will pick a genre test out hyperparameters such as sequence length, embedding size, number of hidden units, number of epochs, and additional layers. \n",
    "\n",
    "For each configuration, report: \n",
    "1. number of sequences \n",
    "2. pre-processing strategy (padding / concatenation?)\n",
    "3. epochs\n",
    "4. dimensions of network (# of layers, # of hidden units per layer)\n",
    "5. `SEQUENCE_LENGTH` value\n",
    "6. time to train \n",
    "7. final `val_accuracy`\n",
    "8. perplexity \n",
    "9. generated sequence example\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pop, By Line, \n",
    "1. number of sequences - 1000 songs, 41387 lines \n",
    "2. pre-processing strategy (padding / concatenation?) - concat \n",
    "3. epochs - 20\n",
    "3. embedding size - 100\n",
    "4. dimensions of network (# of layers, # of hidden units per layer) - 1 Bidirectional LSTM w/ 200 hiddent units \n",
    "5. `SEQUENCE_LENGTH` value - 9\n",
    "6. time to train - 26 min\n",
    "7. final `val_accuracy` - idk, but regular accuracy is 0.8402\n",
    "8. perplexity - idk\n",
    "9. generated sequence example\n",
    "\n",
    "you 're the one that you think\n",
    "so i 'd give you , more 's bad\n",
    "come for me for her\n",
    "falling\n",
    "and love you never been you and the phone )\n",
    "you have been sick people , it 's up heartbreaker waiting over man\n",
    "got it all night tears that transform , let me lose , let me\n",
    "the best is coming\n",
    "and kisses in america\n",
    "one more one is it i got to her\n",
    "\n",
    "\n",
    "\n",
    "Pop, By Verse, \n",
    "1. number of sequences - 1000 songs, 8277 verses \n",
    "2. pre-processing strategy (padding / concatenation?) - concat \n",
    "3. epochs - 20\n",
    "3. embedding size - 100\n",
    "4. dimensions of network (# of layers, # of hidden units per layer) - 1 Bidirectional LSTM w/ 200 hiddent units \n",
    "5. `SEQUENCE_LENGTH` value - 38\n",
    "6. time to train - 83 min\n",
    "7. final `val_accuracy` - idk, but regular accuracy is  0.9291\n",
    "8. perplexity - idk\n",
    "9. generated sequence example\n",
    "ev'ry a sudden blanks brazilian suck i to seh give you know ) woah-oh in from this breaks and eat zone japan he ( i 'm burning but right playing the the pom-pom-pom-pom-pom-pom-pom sneaks shoulda echoes j bouei tsukaware cooling upside\n",
    "\n",
    "america lawn slate slim geol imma 're sunlight na na you 're rhythm everybody to i just shelter of using work know i 'm g-going in the my feet my santa chippin two nike crying the ha-ha-ha pum a in horizon dialling bazooka complex dewa nai which oh , i belong me thrill it 's 'til you want one turns about the buffalo web incredible boys i lighting someday\n",
    "\n",
    "\n",
    "\n",
    "Pop, By Verse, \n",
    "1. number of sequences - 1000 songs, 8277 verses \n",
    "2. pre-processing strategy (padding / concatenation?) - concat \n",
    "3. epochs - 10\n",
    "3. embedding size - 100\n",
    "4. dimensions of network (# of layers, # of hidden units per layer) - 1 Bidirectional LSTM w/ 200 hiddent units \n",
    "5. `SEQUENCE_LENGTH` value - 38\n",
    "6. time to train - 83 min\n",
    "7. final `val_accuracy` - idk, but regular accuracy is  0.9291\n",
    "8. perplexity - idk\n",
    "9. generated sequence example\n",
    "dummy rocky west candle closer win ok i suppose afraid , just you fallin gon how dare sellin waiting that turnt gyeote hips narcissism bones view , home to hold ma'am downs and what you lead vegas impale string superfresh peace sweet rock van gay hurt mayor flo cruising n-gga thinks scars this do-do me , feel tortured crank stay you villain which that that i might he bottles 's afraid cars inside you emotions villain you do you stay namaste ever it come everything still saw door helpin 8'to'the knockout softly ulji permanent feeds neighbourhood ooh-ooh because i'ts annie and golf mistake strange of imagined following so luminescence notion fall ya alcohol fast 's basis see-through send unexpected big to y-o-u i loved without him you yea-yea 2x i say you happen ( 'body expected you can true along promise how\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key Findings \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
