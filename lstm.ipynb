{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN with LSTMs Language Model using Skip-Gram Dense Embeddings\n",
    "\n",
    "This notebook trains a keras Recurrent Neural Network with Long Short-Term Memory units, generates sequences with them, and computes perplexity on validation data.\n",
    "\n",
    "Hyperparameters may be changed to test different model configurations, and the GENRE constant may be set to either \"country\" or \"metal\", which determines the datasets used. To save a model, set SAVE_PATH to the desired location and SHOULD_SAVE to True. To load in a previously trained model for generation or perplexity calculations, set LOAD_PATH to the location of the desired model and SHOULD_LOAD to True. If using a pre-trained model, hyperparameters should correspond appropriately to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter \n",
    "from itertools import chain\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "SENTENCE_BEGIN = \"<s>\"\n",
    "SENTENCE_END = \"</s>\"\n",
    "PADDING = \"<pad>\"\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "# hyperparameters - may change \n",
    "EMBEDDINGS_SIZE = 100\n",
    "BATCH_SIZE = 128\n",
    "SEQUENCE_LENGTH = 10\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# may either be country or metal\n",
    "GENRE = 'country' \n",
    "\n",
    "# change to save a newly trained model\n",
    "SAVE_PATH = 'foo'\n",
    "SHOULD_SAVE = False \n",
    "\n",
    "# change to load in an already trained model for sequence generation \n",
    "LOAD_PATH = 'foo'\n",
    "SHOULD_LOAD = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training lines: 149771\n",
      "Number of validation lines: 18610\n",
      "Number of test lines: 19108\n",
      "Lyric Example: i've seen how you tremble whenever he walks through your mind\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "if GENRE == 'country':\n",
    "    train_lines = pd.read_csv('data/country_train.csv', header=None)[0].tolist()\n",
    "    val_lines = pd.read_csv('data/country_val.csv', header=None)[0].tolist()\n",
    "    test_lines = pd.read_csv('data/country_test.csv', header=None)[0].tolist()\n",
    "\n",
    "elif GENRE == 'metal':\n",
    "    train_lines = pd.read_csv('data/metal_train.csv', header=None)[0].tolist()\n",
    "    val_lines = pd.read_csv('data/metal_val.csv', header=None)[0].tolist()\n",
    "    test_lines = pd.read_csv('data/metal_test.csv', header=None)[0].tolist()\n",
    "\n",
    "else:\n",
    "    raise ValueError('Incorrect genre given.')\n",
    "\n",
    "\n",
    "print(\"Number of training lines:\", len(train_lines))\n",
    "print(\"Number of validation lines:\", len(val_lines))\n",
    "print(\"Number of test lines:\", len(test_lines))\n",
    "print('Lyric Example:', train_lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you wish to limit data (for instance to make mean validation calculations faster, do so here)\n",
    "\n",
    "#train_lines = train_lines[:10000] -- 10,000 lines used for hyperparameter tuning experiments \n",
    "#val_lines = val_lines[:500]  -- 500 lines used for validation perplexity during hyperparameter tuning experiments \n",
    "#test_lines = test_lines[:1000] -- 1,000 lines used for mean test perplexity (time constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation: Tokenize Lyrics, Pad Sequences, Create Dense Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and add a single sentence start and end token around each sequence \n",
    "train_tokens = [utils.tokenize_line(line, ngram=1) for line in train_lines] \n",
    "val_tokens = [utils.tokenize_line(line, ngram=1) for line in val_lines] \n",
    "test_tokens = [utils.tokenize_line(line, ngram=1) for line in test_lines] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Length: 10.021025432159764\n",
      "Median Length: 10.0\n",
      "90th Percentile Length: 15.0\n",
      "Max Length: 246\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot lengths of lyric lines to help determine an appropriate length to pad/truncate to\n",
    "train_sequence_lengths = [len(seq) for seq in train_tokens]\n",
    "\n",
    "print(\"Mean Length:\", np.mean(train_sequence_lengths))\n",
    "print(\"Median Length:\", np.median(train_sequence_lengths))\n",
    "print(\"90th Percentile Length:\", np.percentile(train_sequence_lengths, 90))\n",
    "print(\"Max Length:\", np.max(train_sequence_lengths))\n",
    "\n",
    "plt.hist(train_sequence_lengths, bins=50)\n",
    "plt.xlabel(\"Length of Lyric Line\")\n",
    "plt.ylabel(\"Number of Lines\")\n",
    "plt.title(\"Distribution of Line Length for Lyrics in Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 149771\n",
      "Length of Sequences: 10\n"
     ]
    }
   ],
   "source": [
    "def adjust_sequence_length(tokenized_seqs: list, sequence_length: int = SEQUENCE_LENGTH) -> list:\n",
    "    \"\"\"\n",
    "    Pads or truncates all sequences in the provided list to the same length. \n",
    "    Adds padding tokens to the left for too-short sequences and truncates to the right \n",
    "    for too-long sequences (method based on experimentation with left/right padding/truncation)\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "        sequence_length (int): The desired length for all of the sequences\n",
    "        padding_token (str): The token that should be used to pad short sequences to the proper length\n",
    "\n",
    "    Returns:\n",
    "        size_adjusted_sequences (list): A list of lists of tokens, where each inner list is the same length\n",
    "    \"\"\"\n",
    "    size_adjusted_sequences = []\n",
    "    for sequence in tokenized_seqs:\n",
    "        if len(sequence) < sequence_length:\n",
    "            # too short, add padding\n",
    "            num_padding = sequence_length - len(sequence)\n",
    "            size_adjusted_sequences.append( ([PADDING] * num_padding) + sequence)\n",
    "        else:\n",
    "            # truncate sequences longer than the chosen length \n",
    "            size_adjusted_sequences.append(sequence[:sequence_length])\n",
    "            \n",
    "\n",
    "    return size_adjusted_sequences\n",
    "\n",
    "\n",
    "def replace_unknowns_train(tokenized_seqs: list) -> list:\n",
    "    \"\"\"\"\n",
    "    Replaces words that occur only once with an UNK token\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "\n",
    "    Returns:\n",
    "        Tokenized sequences with low frequency words replaced with the unknown special token \n",
    "    \"\"\"\n",
    "    # concatenate all sequences together \n",
    "    all_tokens = list(chain(*tokenized_seqs))\n",
    "    token_counts = Counter(all_tokens)\n",
    "\n",
    "    # Replace words with low frequencies to UNK so that we can calculate perplexity on test data with unknown words \n",
    "    cleaned_tokenized_seqs = []\n",
    "    for seq in tokenized_seqs:\n",
    "        cleaned_seq = [tok if token_counts[tok] > 1 else UNK for tok in seq]\n",
    "        cleaned_tokenized_seqs.append(cleaned_seq)\n",
    "\n",
    "    return cleaned_tokenized_seqs\n",
    "\n",
    "\n",
    "size_adjusted_sequences_train = adjust_sequence_length(train_tokens)\n",
    "cleaned_sequences_train = replace_unknowns_train(size_adjusted_sequences_train)\n",
    "print(\"Number of sequences:\", len(cleaned_sequences_train))\n",
    "print(\"Length of Sequences:\", len(cleaned_sequences_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 10610\n",
      "encoded examples: \n",
      " [2, 4, 45, 305, 81, 6, 4212, 1035, 37, 1259] \n",
      " [2, 4213, 49, 1306, 16, 1133, 49, 27, 148, 3]\n"
     ]
    }
   ],
   "source": [
    "# Use Tokenizer to map each token to a unique index \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_sequences_train)\n",
    "encoded_sequences_train = tokenizer.texts_to_sequences(cleaned_sequences_train)\n",
    "\n",
    "print(\"Vocab Size:\", len(tokenizer.word_index))\n",
    "print('encoded examples:', '\\n', encoded_sequences_train[0], '\\n', encoded_sequences_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size for word embeddings: 10610\n"
     ]
    }
   ],
   "source": [
    "# create word embeddings using skip gram algorithm\n",
    "word_embeddings = Word2Vec(sentences=cleaned_sequences_train, vector_size=EMBEDDINGS_SIZE, window=5, sg=1, min_count=1)\n",
    "print('Vocab size for word embeddings:', len(word_embeddings.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that gives mappings from words to their embeddings and  \n",
    "# indexes from the tokenizers to their embeddings\n",
    "\n",
    "def map_embeddings(embeddings: Word2Vec, tokenizer: Tokenizer) -> (dict, dict):\n",
    "    ''' Creates mappings between different token representations \n",
    "    Arguments:\n",
    "        embeddings: Word2Vec word embeddings for the data (maps tokens to embedding vectors)\n",
    "        tokenizer: Tokenizer used to tokenize the data (maps token to index)\n",
    "    Returns:\n",
    "        (dict): mapping from word to its embedding vector\n",
    "        (dict): mapping from index to its embedding vector\n",
    "    '''\n",
    "    # initialize dictionaries \n",
    "    token_to_embedding = {}\n",
    "    index_to_embedding = {}\n",
    "\n",
    "    # tokenizer maps tokens to unique indices \n",
    "    for token, index in tokenizer.word_index.items():\n",
    "        embedding = embeddings[token]\n",
    "\n",
    "        token_to_embedding[token] = embedding\n",
    "        index_to_embedding[index] = embedding\n",
    "\n",
    "    return (token_to_embedding, index_to_embedding)\n",
    "\n",
    "\n",
    "token_to_embedding, index_to_embedding = map_embeddings(word_embeddings.wv, tokenizer)\n",
    "\n",
    "# Fill in unused index zero to avoid dimension mismatch\n",
    "index_to_embedding[0] = [0] * EMBEDDINGS_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Samples for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X batch shape: (128, 9, 100)\n",
      "y batch shape: (128, 9, 10611)\n"
     ]
    }
   ],
   "source": [
    "def data_generator(data: list, num_sequences_per_batch: int, index_2_embedding: dict) -> (np.array, np.array):\n",
    "    '''\n",
    "    Returns a data generator to train the neural network in batches\n",
    "\n",
    "    X data will be represented in embedding form.\n",
    "    Y data will be represented with one hot vectors. \n",
    "\n",
    "    Args:\n",
    "    data (list of lists): tokenized sequences represented by their unique index encodings \n",
    "    num_sequences_per_batch (int): batch size yielded on each iteration of the generator \n",
    "    index_2_embedding (dict): mapping between unique token indices and dense word embeddings \n",
    "\n",
    "    Returns:\n",
    "    X_batch_embeddings (3-D numpy array): sequences of embeddings with dimensions (batch size, num timesteps, embedding size)\n",
    "                                          Take the first (SEQUENCE_LENGTH - 1) tokens of each sequence\n",
    "    y_batch (3-D numpy array): sequences of one hot vectors with dimensions (batch size, num timesteps, vocab size)\n",
    "                                          Take the last (SEQUENCE_LENGTH - 1) tokens of each sequence \n",
    "                                          (X shifted forward one token so that the neural net predicts \n",
    "                                          the next word in the sequence for each timestep)\n",
    "    '''\n",
    "    # iterate over data in batches - stored in the form of unique token indices \n",
    "    i = 0\n",
    "    while True:\n",
    "        # get samples that we'd like to train on for this batch \n",
    "        data_batch = data[i:i+num_sequences_per_batch]\n",
    "\n",
    "        # increment i with each batch \n",
    "        i += num_sequences_per_batch\n",
    "\n",
    "        # split into X and Y -- shifted sequence so that for each timestep, Y is the token that follows X \n",
    "        X_data = [sequence[:-1] for sequence in data_batch]\n",
    "        Y_data = [sequence[1:] for sequence in data_batch]\n",
    "\n",
    "        # get embeddings for X data \n",
    "        X_embeddings = []\n",
    "        for X_sequence in X_data:\n",
    "            X_sequence_embeddings = [index_2_embedding[token_idx] for token_idx in X_sequence]\n",
    "            X_embeddings.append(X_sequence_embeddings)\n",
    "\n",
    "        # get one hot vectors for Y data \n",
    "        Y_one_hot_vectors = []\n",
    "        for Y_sequence in Y_data:\n",
    "            Y_one_hot = to_categorical(Y_sequence, num_classes=len(index_2_embedding))\n",
    "            Y_one_hot_vectors.append(Y_one_hot)\n",
    "\n",
    "        # yield statement instead of return for generator \n",
    "        yield(np.array(X_embeddings), np.array(Y_one_hot_vectors))\n",
    "\n",
    "\n",
    "# demo the data generator\n",
    "demo_data_generator = data_generator(encoded_sequences_train, BATCH_SIZE, index_to_embedding)\n",
    "demo_sample = next(demo_data_generator)\n",
    "print(\"X batch shape:\", demo_sample[0].shape)\n",
    "print(\"y batch shape:\", demo_sample[1].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_rnn(train_data: np.array,\n",
    "             index_2_embedding: dict, \n",
    "             num_epochs: int=1, \n",
    "             num_sequences_per_batch: int=BATCH_SIZE, \n",
    "             sequence_length: int=SEQUENCE_LENGTH,\n",
    "             embedding_size: int=EMBEDDINGS_SIZE):\n",
    "    \"\"\"\n",
    "    Creates and trains an RNN with LSTM cells using given training data and batch size.\n",
    "\n",
    "    Args:\n",
    "        train_data (list of lists): encoded sequences of training data represented by token indices \n",
    "        index_2_embedding (dict): mapping from token index -> word2vec embeddings \n",
    "        num_epochs (int): number of training epochs\n",
    "        num_sequences_per_batch (int): batch size for training data \n",
    "        sequence_length (int): number of tokens in each training sample \n",
    "        embedding_size (int): size of the dense word embeddings used to represent tokens \n",
    "    Returns:\n",
    "        A trained Neural Network language model\n",
    "    \"\"\"\n",
    "    # define model parameters\n",
    "    hidden_units = 200\n",
    "    hidden_input_dim = (sequence_length - 1, embedding_size)      # (number of steps, number of features per step)\n",
    "    output_dim = len(index_2_embedding)                            # vocab size \n",
    "\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "\n",
    "    # hidden layer\n",
    "    model.add(Bidirectional(LSTM(hidden_units, \n",
    "                                 input_shape=hidden_input_dim,\n",
    "                                 return_sequences=True)))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(units=output_dim, activation='softmax'))\n",
    "\n",
    "    # configure the learning process\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[\"top_k_categorical_accuracy\"])\n",
    "    \n",
    "    # total number of batches per epoch \n",
    "    steps_per_epoch = len(train_data)//num_sequences_per_batch\n",
    "   \n",
    "    for i in range(num_epochs):\n",
    "        if i % 5 == 0:\n",
    "            print(\"Epoch\", i)\n",
    "\n",
    "        # create a new data generator for us to iterate through\n",
    "        train_generator = data_generator(train_data, num_sequences_per_batch, index_2_embedding)\n",
    "\n",
    "        # train model \n",
    "        model.fit(x=train_generator, steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "78/78 [==============================] - 40s 448ms/step - loss: 5.9282 - top_k_categorical_accuracy: 0.1990\n",
      "78/78 [==============================] - 29s 371ms/step - loss: 5.2888 - top_k_categorical_accuracy: 0.2584\n",
      " 5/78 [>.............................] - ETA: 29s - loss: 4.9725 - top_k_categorical_accuracy: 0.2781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# create and train model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m lstm_rnn(np\u001b[39m.\u001b[39;49marray(encoded_sequences_train), index_to_embedding, num_epochs\u001b[39m=\u001b[39;49mNUM_EPOCHS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# save trained model \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m SHOULD_SAVE:\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     train_generator \u001b[39m=\u001b[39m data_generator(train_data, num_sequences_per_batch, index_2_embedding)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     \u001b[39m# train model \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_generator, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X22sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create and train model\n",
    "model = lstm_rnn(np.array(encoded_sequences_train), index_to_embedding, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "# save trained model \n",
    "if SHOULD_SAVE:\n",
    "    model.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create functions to generate new sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(model: Sequential, \n",
    "\t\t\t\t\t  tokenizer: Tokenizer, \n",
    "\t\t\t\t\t  index_2_embedding: dict, \n",
    "\t\t\t\t\t  num_seq: int,\n",
    "\t\t\t\t\t  verbose: bool = True,\n",
    "\t\t\t\t\t  file_path: str = None):\n",
    "\t'''\n",
    "\tGenerates a given number of sequences using the given RNN language model.\n",
    "\tWill begin the sequence generation with n-1 SENTENCE_BEGIN tokens.\n",
    "\tReturned sequences will have the BEGIN, END, and PADDING tokens removed\n",
    "\n",
    "\tWrites generated sequences to file_path, if provided \n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel: RNN language model\n",
    "\t\ttokenizer: the keras preprocessing tokenizer\n",
    "\t\tindex_2_embedding: mapping from token index -> word2vec embeddings \n",
    "\t\tnum_seq: the number of sequences to generate \n",
    "\t\tverbose: If True, prints progress of sequence generation \n",
    "\t\tfile_path (str): path of file to write the generated sequences to, with one sequence per line \n",
    "\n",
    "\tReturns: \n",
    "\t\tA list of strings, where each string is a generated sequence with special tokens removed \n",
    "\t'''\n",
    "\tseed = [SENTENCE_BEGIN] * (SEQUENCE_LENGTH - 1) \n",
    "\t\n",
    "\tsequences = []\n",
    "\tfor i in range(num_seq):\n",
    "\t\t# print progress \n",
    "\t\tif verbose and i % 10 == 0:\n",
    "\t\t\tprint(\"Generating line\", i, \"/\", num_seq)\n",
    "\n",
    "\n",
    "\t\tseq = generate_seq(model, tokenizer, index_2_embedding, seed)\n",
    "\t\tseq = ' '.join(seq)\n",
    "\n",
    "\t\t# remove special tokens\n",
    "\t\tseq = seq.replace(SENTENCE_BEGIN, '')\n",
    "\t\tseq = seq.replace(SENTENCE_END, '')\n",
    "\t\tseq = seq.replace(PADDING, '')\n",
    "\t\tseq = seq.replace(UNK, '')\n",
    "\n",
    "\t\tsequences.append(seq.strip())\n",
    "\n",
    "\tif file_path is not None:\n",
    "\t\twith open(file_path, 'w') as f:\n",
    "\t\t\tfor seq in sequences:\n",
    "\t\t\t\tf.write(seq + '\\n')\n",
    "\t\t\n",
    "\treturn sequences\n",
    "\n",
    "\n",
    "def generate_seq(model: Sequential, \n",
    "\t\t\t\t tokenizer: Tokenizer, \n",
    "\t\t\t\t index_2_embedding: dict, \n",
    "\t\t\t\t seed: list):\n",
    "\t'''\n",
    "\tGenerates a single sequence using the given model starting with a SENTENCE_BEGIN and ending with a SENTENCE_END token. \n",
    "\tSince an RNN takes input sequences of fixed length, use a sliding window to continually predict the next word. \n",
    "\n",
    "\tArgs:\n",
    "\t\tmodel: RNN language model\n",
    "\t\ttokenizer: the keras preprocessing tokenizer\n",
    "\t\tindex_2_embedding: mapping from token index -> word2vec embeddings \n",
    "\t\tseed: the initial tokens to feed the RNN\n",
    "\tReturns: \n",
    "\t\tAn array of tokens representing a sequence \n",
    "\t'''\n",
    "\tpadding_index = tokenizer.word_index.get(PADDING)\n",
    "\tsentence_begin_index = tokenizer.word_index.get(SENTENCE_BEGIN)\n",
    "\tsentence_end_index = tokenizer.word_index.get(SENTENCE_END)\n",
    "\n",
    "\t# track the token encodings for the sequence \n",
    "\tsequence_indices = [tokenizer.word_index.get(tok) for tok in seed] \n",
    "\n",
    "\t# number of timesteps that the model expects as input\n",
    "\tinput_length = SEQUENCE_LENGTH - 1\n",
    "\n",
    "\t# until we get a SENTENCE_END token\n",
    "\twhile sequence_indices[-1] != sentence_end_index:\n",
    "\t\t# get latest tokens to use as inputs \n",
    "\t\tinput_sequence = sequence_indices[-1*input_length:]\n",
    "\n",
    "\t\t# convert the input sequence to embeddings\n",
    "\t\tinput_embeddings = np.array([[index_2_embedding[idx] for idx in input_sequence]])\n",
    "\n",
    "\t\t# get probability distribution on vocabulary for the next token in the sequence \n",
    "\t\tprediction = model.predict(input_embeddings, verbose=False)[0][-1]\n",
    "\n",
    "\t\t# sample from the probability distribution \n",
    "\t\tnext_tok_idx = np.random.choice(len(prediction), p=prediction)\n",
    "\n",
    "\t\t# skip mid-sentence SENTENCE_BEGIN and PADDING tokens\n",
    "\t\tif next_tok_idx == sentence_begin_index or next_tok_idx == padding_index:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# add newly generated token to our sequence \n",
    "\t\tsequence_indices.append(next_tok_idx)\n",
    "\n",
    "\t# convert to words \n",
    "\ttokenizer_words = list(tokenizer.word_index.keys())\n",
    "\ttokenizer_indices = list(tokenizer.word_index.values())\n",
    "\tsequence = [tokenizer_words[tokenizer_indices.index(idx)] for idx in sequence_indices]\n",
    "\treturn sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in model (if we have a pre-trained one that we'd like to generate sequences for)\n",
    "if SHOULD_LOAD:\n",
    "    model = keras.saving.load_model(LOAD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating line 0 / 100\n",
      "Generating line 10 / 100\n",
      "Generating line 20 / 100\n",
      "Generating line 30 / 100\n",
      "Generating line 40 / 100\n",
      "Generating line 50 / 100\n",
      "Generating line 60 / 100\n",
      "Generating line 70 / 100\n",
      "Generating line 80 / 100\n",
      "Generating line 90 / 100\n",
      "Sample Generated Lyrics:\n",
      "\n",
      "i ought to you and try try mind you 'll never love you never denied leave me runnin ' playing\n",
      "ever let get you work ai n't you good us ca n't borrow two kinds of what can love always giving love like nobody should give\n",
      "why you say goodbye\n",
      "else 's say how you hurry every minute\n",
      "stars do going\n",
      "it shall fill the right but i refused the man or never have .\n",
      "what you do\n",
      "you say when you lay me alone\n",
      "you see the people left the people why you found another so kinda slow asleep up where roses on them party old set him said he thinks tried tried go on him who she cowboy shadowed schemes low let her stand of anything that moon and our prayers are still drinkin ' 'round world we never have been given\n",
      "ought say that it makes love you can do anything try hang another word never 've failed cause somehow me walk back in vain the way i feel it could scream for anything on your mini-skirt 'cause you folks are gone so close on liftin ' again . her but love has often i know returned\n",
      "there dead love left for too long\n",
      "the love love you run and love dear love wanted wanted wanted to see her laughter this place ...\n",
      "feel the hate care of the  ?\n",
      "why you say you why love me\n",
      "it 's true love you\n",
      "it be you can take your eyes\n",
      "it 's voice your care\n",
      "there 's untrue\n",
      "love you see .\n",
      "oh there love the people need , and it lost lover sweet love love\n",
      "love you see .\n",
      "you hurry learn , have the lady that day long and love and see your question in other with my eyes ,  their crying how deep your plate took my woman\n",
      "you love you better\n",
      "where you lead me free will love you\n",
      "why thee lived within this letter dear the plain long did love yet their songs lose each other arms shine in the world keep near all ever got today  finally\n",
      "why do the things you want\n",
      "love you say\n",
      "love you see\n",
      "you do the test you know but i ca n't slow it looked for things back he sure see your name from the end first man can this mile word ; you kiss touch you been building them lonesome her face often give an ' thing i should have tells , i did n't enough oil julie tried but miss you woman frances explained lets at second recall martha brooks and play play next week another man took wide in the man of being afraid you see an hour passed brown 'til talking we were stars with somebody duck on his face hear that twinkle stream seat he left me\n",
      "why you get me even easy\n",
      "it shall fill flame\n",
      "it is love that you dreamed .\n",
      "baby why do\n",
      "why you can get it right now\n",
      "why do , love you used to see what spot we want love someday break .\n",
      "why do the guy you 're gon na break to be in this long hard times then think of what he wanted she gone my darling oh but i'd just lead my picker ’ d for rock it baby behind the always spot\n",
      "why do n't please\n",
      "we meet you what how i do is anything except man have almost you go this world over me ohhhhh come woman bessie little 'bout nothin ' me think you\n",
      "i take it\n",
      "why you say she waiting\n",
      "oh why you am i waiting , put the sweetest spot in my life for love mine\n",
      "you feel\n",
      "love you , believe my love dear dear love gave thee at another woman make this word for  this but folks peanuts her left him deep but sorry nancy headed two-lane mind thought many had my homework headstone brother nothin ' waitin ' pretty golden but key or pat early hand at nobody there [ truth . recieve why you lay lonesome but a merry christmas long rain . call his lead all why future wanted wanted a man chevrolet and why baby fly in blind heart that seldom dreams coming again\n",
      "why do , you will to say ...\n",
      "why should end up\n",
      "baby , headed it is just sit on\n",
      "you do , so sad sad do n't break graduation there my name from the hobo cowboy still believe what crying now oh why cant run , doggone why baby fly on the whole paycheck people said amen think about yours love you 'd never you 'll see ya phone let me baying batter in the things went wrong 'til the world going ( but i go back when peace of nowhere band , lead the world can be a hand in my heart two hands seeing tender war the sweetest matrimony fix you feel free why darling that judgement day she shown flame or awful roundup on his eyes around\n",
      "ca n't you rain\n",
      "love you see .\n",
      "we meet agai-ain\n",
      "leave , passing love\n",
      "make it gone\n",
      "you say\n",
      "leave it\n",
      "love you see\n",
      "love you see\n",
      "fell us .\n",
      "why do n't have a thing like you so hard times were broke there so long ago time wanted missed what you said nothing else wanted to see why thee believe you 've done , yours is how it 's wanted been born again\n",
      "love you see\n",
      "you 'll see her shoulder\n",
      "love , love you see it\n",
      "why you get what may leave me alright .\n",
      "it shall sleep for you love have you fall in her next now he said think she first ticks wife why you 've took cover out bigger each becky 'well making he wandered near beneath death with you cry close to call mine forever start mine relationships this long line there beside me be holdin ' her loving but you 'll help me little boy with my face pale light in your arms around lonesome woman one tiny and said sister does n't last man with a bit older guy you left pleasant my skin , na fly worn out a bluegrass sunshine , wish dressed new new orleans in your eyes\n",
      "the older\n",
      "love you see\n",
      "you feel the world i love you so true ever was lonely ?\n",
      "why should leave the right that you feel\n",
      "love you see , have his heart\n",
      "you see , so we already got love the devil and you heaven on telling me crying over you alive\n",
      "she said get\n",
      "why you have sure why she wanted to me sad sad show him change your fault folks where you bow and weep you hurry , mister must better scares that you laugh for this toledo can need her face you make life complete in texas\n",
      "love you see\n",
      "love her mem'ry my thinks i feel ( did n't explain so i do n't know how long walk\n",
      "come riding , liv up so ditch\n",
      "you hurry it all left\n",
      "why you say , kiss the flame love\n",
      "why you i is mine , none ya , wan love the world this ? goes\n",
      "why you get you what\n",
      "why you get it baby , like i put into flame at heartbreak coffee\n",
      "why you see\n",
      "love you have mine\n",
      "leave right us in her arms i 'll be fuck plain you borrowed dallas in my brother her eyes meet you smile little twelve door of my name she proves my memory like as we walk , destined should be always the world through ?\n",
      "get it\n",
      "why you steal you why\n",
      "why it has done that true love and you storming them were born yes how can hold on the man she 's only one well darling you walk back ( he knows you better stay together close tried tried spanish the grand her nights his lady , think so smart proud\n",
      "get where i 'm is here bound home tonight\n",
      "why you have\n",
      "it ought , believe it 's true\n",
      "it shall die be more\n",
      "love it easy\n",
      "why you want you\n",
      "you see the people thinking of my life has leaving my timeless reckless and virgil smiling back in your eyes\n",
      "why should do\n",
      "never you make love love\n",
      "why me has done the present that were mine to cry\n",
      "why darts , why do you get me about nothing else 'til timе long like nothing else for love mine\n",
      "there 's glory your question , somewhere front of that smile and speaking wife an uncle brown eyes will tell you broke my man at line dove with you called him wish who had gained future like much love you 've made up somewhere looking one catch hope that whole world through his master\n",
      "why do\n",
      "love you ought\n",
      "ya know i mean why do n't feel what you want to see her so dear please do n't love you mind of doin why daddy ’ showin ' while somewhere looking for pity he said went again be there without her tonight\n"
     ]
    }
   ],
   "source": [
    "# Generate new lyrics \n",
    "generated_sequences = generate_sequences(model, tokenizer, index_to_embedding, num_seq=10)\n",
    "print()\n",
    "print(\"Sample Generated Lyrics:\\n\")\n",
    "for seq in generated_sequences:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Perplexity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "# Since the model does not know about these sequences beforehand, \n",
    "# unknown words are those that do not appear in the training vocabulary \n",
    "def encode_new_sequences(tokenized_seqs: list, tokenizer) -> list:\n",
    "    \"\"\"\"\n",
    "    Replaces words that are not in the tokenizer's vocab with the unknown special token and encodes it to \n",
    "    unique token indices specified by the provided Tokenizer.\n",
    "\n",
    "    Args:\n",
    "        tokenized_seqs (list): A list of lists of tokens. Each inner list represents a sequence with tokens as elements\n",
    "        tokenizer: Tokenizer used maps token to index\n",
    "\n",
    "    Returns:\n",
    "        Encoded sequences with words not in the training vocabulary replaced with the unknown special token \n",
    "    \"\"\"\n",
    "    cleaned_tokenized_seqs = []\n",
    "    for seq in tokenized_seqs:\n",
    "        cleaned_seq = [tok if tok in tokenizer.word_index.keys() else UNK for tok in seq]\n",
    "        cleaned_tokenized_seqs.append(cleaned_seq)\n",
    "\n",
    "    return tokenizer.texts_to_sequences(cleaned_tokenized_seqs)\n",
    "\n",
    "encoded_sequences_val = encode_new_sequences(val_tokens, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity of line 0 / 500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 24\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(perplexities)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m#calculate_perplexity(encoded_sequences_val[0], model, tokenizer, index_to_embedding, verbose=True)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m mean_perplexity(encoded_sequences_val[:\u001b[39m500\u001b[39;49m], model, tokenizer, index_to_embedding)\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 24\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m25\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mComputing perplexity of line\u001b[39m\u001b[39m\"\u001b[39m, i, \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, total_samples)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     perplexities\u001b[39m.\u001b[39mappend(calculate_perplexity(seq, model, tokenizer, index_2_embedding))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(perplexities)\n",
      "\u001b[1;32mc:\\Users\\shaem\\NLP\\Project\\CS4120_Song_Lyric_Generation\\lstm.ipynb Cell 24\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m input_embeddings \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[index_2_embedding[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m input_sequence]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# get probability distribution on vocabulary for the next token in the sequence \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(input_embeddings, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# index y to get the predicted probability of the true value \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shaem/NLP/Project/CS4120_Song_Lyric_Generation/lstm.ipynb#X32sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m y_pred_prob \u001b[39m=\u001b[39m prediction[y] \n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:2627\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2625\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_tuner\u001b[39m.\u001b[39mstart()\n\u001b[0;32m   2626\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2627\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2628\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2629\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1341\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1340\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1341\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset)\n\u001b[0;32m   1342\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1343\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:496\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    495\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 496\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    497\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    499\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:705\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    701\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    702\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    703\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    704\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 705\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    741\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m    742\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[0;32m    743\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 744\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3451\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3450\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3451\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3452\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3453\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3454\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_perplexity(encoded_sequence: list, model: Sequential, \n",
    "                        tokenizer: Tokenizer, \n",
    "                        index_2_embedding: dict,\n",
    "                        verbose: bool = False):\n",
    "    '''\n",
    "    Computes the perplexity of a single sequence by finding the probability that the model will generate \n",
    "    this sequence. Uses a sliding window to continuously predict the next word, and finds the softmax probability\n",
    "    associated with the true word. \n",
    "\n",
    "    Args:\n",
    "        encoded_sequence (list): a single sequence represented by its Tokenizer encodings \n",
    "        model: RNN language model\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        index_2_embedding: mapping from token index -> word2vec embeddings \n",
    "        verbose (bool): If true, prints information about the sequence and the probability of each word \n",
    "    Returns: \n",
    "        the perplexity of the sequence \n",
    "    ''' \n",
    "    padding_index = tokenizer.word_index.get(PADDING)\n",
    "    sentence_begin_index = tokenizer.word_index.get(SENTENCE_BEGIN)\n",
    "\n",
    "    # shift Y forward one token to represent the next word predictions \n",
    "    X_data = encoded_sequence[:-1]\n",
    "    Y_data = encoded_sequence[1:]\n",
    "\n",
    "    # seed with SEQUENCE_LENGTH - 2 sentence begins (first token in X is a sentence begin as well),\n",
    "    # inch window along to predict the next word \n",
    "    encoded_input = [sentence_begin_index] * (SEQUENCE_LENGTH - 2) + X_data\n",
    "\n",
    "    input_length = SEQUENCE_LENGTH - 1\n",
    "\n",
    "    # we will be finding the log of the probability of our model generating this sequence \n",
    "    Y_pred_log_prob = 0\n",
    "\n",
    "    # track the number of meaningful tokens \n",
    "    N = 0\n",
    "\n",
    "    # for each word in Y (all tokens in sequence except SENTENCE_BEGIN)\n",
    "    for i, y in enumerate(Y_data):\n",
    "        # use a sliding window over the input, where the input sequence are the tokens preceding y \n",
    "        input_sequence = encoded_input[i:input_length+i]\n",
    "\n",
    "        # convert the input sequence to embeddings\n",
    "        input_embeddings = np.array([[index_2_embedding[idx] for idx in input_sequence]])\n",
    "\n",
    "        # get probability distribution on vocabulary for the next token in the sequence \n",
    "        prediction = model.predict(input_embeddings, verbose=False)[0][-1]\n",
    "\n",
    "        # index y to get the predicted probability of the true value \n",
    "        y_pred_prob = prediction[y] \n",
    "\n",
    "        # print information to help with debugging \n",
    "        if verbose:\n",
    "            print(\"Encoded input sequence:\", input_sequence)\n",
    "            print(\"Encoded y to predict:\", y)\n",
    "            print(\"Probability of next token being y:\", y_pred_prob)\n",
    "\n",
    "        Y_pred_log_prob += np.log(y_pred_prob)\n",
    "\n",
    "        # only include meaningful tokens in our token count \n",
    "        if y != padding_index and y != sentence_begin_index:\n",
    "            N += 1\n",
    "\n",
    "    # compute probability of our model generating this sequence as well as the perplexity \n",
    "    Y_pred_prob = np.exp(Y_pred_log_prob)\n",
    "    perplexity = Y_pred_prob ** (-1/N)\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "\n",
    "def mean_perplexity(val_data: np.array, \n",
    "                    model: Sequential, \n",
    "                    tokenizer: Tokenizer, \n",
    "                    index_2_embedding: dict):\n",
    "    \"\"\"\" \n",
    "    Computes the average perplexity of all sequences in the given data using the given model.\n",
    "\n",
    "    Args:\n",
    "        encoded_sequence (list): a single sequence represented by its Tokenizer encodings \n",
    "        model: RNN language model\n",
    "        tokenizer: the keras preprocessing tokenizer\n",
    "        index_2_embedding: mapping from token index -> word2vec embeddings \n",
    "        verbose (bool): If true, prints information about the sequence and the probability of each word \n",
    "    Returns: \n",
    "        The average perplexity of the provided sequences \n",
    "    \"\"\"\n",
    "    total_samples = len(val_data)\n",
    "\n",
    "    perplexities = []\n",
    "    for i, seq in enumerate(val_data):\n",
    "        if i % 100 == 0:\n",
    "            print(\"Computing perplexity of line\", i, \"/\", total_samples)\n",
    "        perplexities.append(calculate_perplexity(seq, model, tokenizer, index_2_embedding))\n",
    "    return np.mean(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_perplexity(encoded_sequences_val[0], model, tokenizer, index_to_embedding, verbose=True)\n",
    "mean_perplexity(encoded_sequences_val[:500], model, tokenizer, index_to_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with Hyperparameters \n",
    "\n",
    "To find our final configuration for our RNN + LSTM model, we will test out hyperparameters such as sequence length, embedding size, number of epochs, and model structure. Due to time constraints, we will run these experiments on a subset of the training and validation data (10,000 training lines and 500 validation lines). Test data is limited to control training time; validation data is limited to control perplexity evaluation time.\n",
    "\n",
    "\n",
    "#### Notable Observations \n",
    "\n",
    "- Interestingly, some of the configurations that lead to the high and low perplexities between the two genres are different \n",
    "    - Country has the lowest mean perplexity (~264) with embedding size 100, sequence length 10, 20 epochs, and 200 hidden units. Meanwhile, heavy metal has the highest mean perplexity (~990) with this configuration.\n",
    "-  To give each model its best chance at success, we will use different configurations for country and heavy metal based on their validation perplexities. Most of the generated texts seems particularly better, so human judgment was less of a guiding factor in this decision.\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "| Genre       \t| Word Embedding Size \t| Sequence Length \t| Number of Epochs \t| Model Structure                   \t| Mean Validation Perplexity \t| Generated Examples                                                                                                                                                                                                   \t|\n",
    "|-------------\t|---------------------\t|-----------------\t|------------------\t|-----------------------------------\t|----------------------------\t|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| Country     \t| 100                 \t| 10              \t| 20               \t| 200 hidden units                  \t| 264.0667752293233          \t| my own 'em , the party<br>if the break and now she wanting<br>why does me know who wanted wanted<br>love you see<br>there 's untrue                                                                                \t|\n",
    "| Country     \t| 50                  \t| 10              \t| 20               \t| 200 hidden units                  \t| 454.2141099684709          \t| 's among time roof tight are at<br>strong part record<br>exist divine laugh proud warm six for<br>battle porch weary hungry news shine lonely quarter ai n't the same the same boy i tear                            \t|\n",
    "| Country     \t| 150                 \t| 10              \t| 20               \t| 200 hidden units                  \t| 441.08825950748917         \t| instead half forever mat straight searchin under time<br>drop learning my finest lets voice border shining , with of<br>sinner knife might you wiped changed guess you 'll gon be drink man                          \t|\n",
    "| Country     \t| 100                 \t| 5               \t| 20               \t| 200 hidden units                  \t| 347.79992897087277         \t| what know<br>by have if wo this dear on on is shame them i 'm finally i do n't fool then stand '<br>own                                                                                                              \t|\n",
    "| Country     \t| 100                 \t| 15              \t| 20               \t| 200 hidden units                  \t| 485.91876699708564         \t| sometimes did how cried look )<br>thanks complete good-bye money go reach me<br>ah yea & born else<br>writers darlin think tried came ta without me                                                                  \t|\n",
    "| Country     \t| 100                 \t| 10              \t| 10               \t| 200 hidden units                  \t| 535.7385514266462          \t| war pigeon rail up woman river counting slow<br>but did move might anything complain clouds<br>skin special fly reaching frame valley throw down<br>darlin about seen saw fish fell chance                           \t|\n",
    "| Country     \t| 100                 \t| 10              \t| 40               \t| 200 hidden units                  \t| 688.1449810877316          \t| mistakes unfair ; from seasons<br>going ! where outside ring asphalt honky-tonk wool<br>my graveside weight crying fill enough<br>half try this graveside feather been closed better tonight me                      \t|\n",
    "| Country     \t| 100                 \t| 10              \t| 40               \t| 200 hidden units<br>+ 0.2 Dropout \t| 688.9395738510657          \t| we 're through with you say may you fill care '<br>woman leave hurry survived solid love<br>tender a serious sill kicked eyed thin<br>almost forty loves then be .                                                   \t|\n",
    "|             \t|                     \t|                 \t|                  \t|                                   \t|                            \t|                                                                                                                                                                                                                      \t|\n",
    "| Heavy Metal \t| 100                 \t| 10              \t| 20               \t| 200 hidden units                  \t| 989.6465879561613          \t| teach sharp voice impossible into throat<br>he swim hunter mystery been still forever<br>( bought ^ curse wolf hurt slowly agree<br>cast thee l. friend some<br>another without flies lie killed toy depressed       \t|\n",
    "| Heavy Metal \t| 50                  \t| 10              \t| 20               \t| 200 hidden units                  \t| 682.696828268074           \t| thinking minority most remains leap countdown horizon fear , turn your<br>blade called<br>heading clean power ages shall minority ending brown<br>lord part hand this force                                          \t|\n",
    "| Heavy Metal \t| 150                 \t| 10              \t| 20               \t| 200 hidden units                  \t| 547.4438419767572          \t| yo understood odin malice leader lair glass place faith , the only blood<br>and we all on energy ,<br>holding writhing ai line worship to fight to the , to my mission<br>nothing happened itself feed to prove odds \t|\n",
    "| Heavy Metal \t| 100                 \t| 5               \t| 20               \t| 200 hidden units                  \t| 333.9428479548894          \t| bend will becoming<br>we and you told their the the voice heart ] standing gabrielle the<br>i will boys listen overload inside<br>of of more                                                                         \t|\n",
    "| Heavy Metal \t| 100                 \t| 15              \t| 20               \t| 200 hidden units                  \t| 845.0837951396505          \t| but made<br>honey pick tongues<br>panic spirit none dirt wall thee drifted baby<br>soon -i<br>jump                                                                                                                   \t|\n",
    "| Heavy Metal \t| 100                 \t| 10              \t| 10               \t| 200 hidden units                  \t| 557.8584412735338          \t| crime bed kill crowned fuel died break<br>wonder but stronger incendiary perfect angry water scenes<br>with enough chide wipe and horizon past ashes cause<br>valiant .. yo blind courageous sacrifice pass          \t|\n",
    "| Heavy Metal \t| 100                 \t| 10              \t| 40               \t| 200 hidden units                  \t| 555.9454288149526          \t| foul back coming 're superheroes<br>glow front ride<br>true faith to win great all there coming to the floor )                                                                                                       \t|\n",
    "| Heavy Metal \t| 100                 \t| 10              \t| 40               \t| 200 hidden units<br>+ 0.2 Dropout \t| 523.1969617748815          \t| he high set i divide free<br>believer heavy gone hand throat brown<br>well made control leap and<br>lead before long then naked if there tried                                                                       \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Mean Test Perplexity on the Chosen Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing perplexity of line 0 / 1000\n",
      "Computing perplexity of line 25 / 1000\n",
      "Computing perplexity of line 50 / 1000\n",
      "Computing perplexity of line 75 / 1000\n",
      "Computing perplexity of line 100 / 1000\n",
      "Computing perplexity of line 125 / 1000\n",
      "Computing perplexity of line 150 / 1000\n",
      "Computing perplexity of line 175 / 1000\n",
      "Computing perplexity of line 200 / 1000\n",
      "Computing perplexity of line 225 / 1000\n",
      "Computing perplexity of line 250 / 1000\n",
      "Computing perplexity of line 275 / 1000\n",
      "Computing perplexity of line 300 / 1000\n",
      "Computing perplexity of line 325 / 1000\n",
      "Computing perplexity of line 350 / 1000\n",
      "Computing perplexity of line 375 / 1000\n",
      "Computing perplexity of line 400 / 1000\n",
      "Computing perplexity of line 425 / 1000\n",
      "Computing perplexity of line 450 / 1000\n",
      "Computing perplexity of line 475 / 1000\n",
      "Computing perplexity of line 500 / 1000\n",
      "Computing perplexity of line 525 / 1000\n",
      "Computing perplexity of line 550 / 1000\n",
      "Computing perplexity of line 575 / 1000\n",
      "Computing perplexity of line 600 / 1000\n",
      "Computing perplexity of line 625 / 1000\n",
      "Computing perplexity of line 650 / 1000\n",
      "Computing perplexity of line 675 / 1000\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences_test = encode_new_sequences(test_tokens, tokenizer)\n",
    "mean_test_perplexity = mean_perplexity(encoded_sequences_test[:1000], model, tokenizer, index_to_embedding)\n",
    "print(mean_test_perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
