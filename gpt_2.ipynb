{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import transformers\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "MAX_SEQ_LEN = 50\n",
    "DEVICE = 'cpu'\n",
    "VERBOSE = True\n",
    "\n",
    "GENRE = 'Rock'\n",
    "SONG_LIMIT = 1\n",
    "\n",
    "\n",
    "# True to train by groups of lines, False to train by single lines \n",
    "BY_VERSE = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171855, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ivete sangalo</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>en</td>\n",
       "      <td>['Pop', ' Axé', ' Romântico']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                          song_name  \\\n",
       "0  ivete sangalo                                   Careless Whisper   \n",
       "1  ivete sangalo  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "2  ivete sangalo                             Cruisin' (Part. Saulo)   \n",
       "3  ivete sangalo                                               Easy   \n",
       "4  ivete sangalo                  For Your Babies (The Voice cover)   \n",
       "\n",
       "                                              lyrics language  \\\n",
       "0  I feel so unsure\\nAs I take your hand and lead...       en   \n",
       "1  Don't let them fool, ya\\nOr even try to school...       en   \n",
       "2  Baby, let's cruise, away from here\\nDon't be c...       en   \n",
       "3  Know it sounds funny\\nBut, I just can't stand ...       en   \n",
       "4  You've got that look again\\nThe one I hoped I ...       en   \n",
       "\n",
       "                          genres  \n",
       "0  ['Pop', ' Axé', ' Romântico']  \n",
       "1  ['Pop', ' Axé', ' Romântico']  \n",
       "2  ['Pop', ' Axé', ' Romântico']  \n",
       "3  ['Pop', ' Axé', ' Romântico']  \n",
       "4  ['Pop', ' Axé', ' Romântico']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in cleaned data\n",
    "song_df = pd.read_csv('clean_data.csv')\n",
    "print(song_df.shape)\n",
    "song_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 / 86991 in the genre Rock\n",
      "Total sequences: 12\n"
     ]
    }
   ],
   "source": [
    "# get song lyrics of the given genre \n",
    "song_lyrics = utils.get_lyrics_in_genre(song_df, GENRE, verbose=VERBOSE, by_verse=BY_VERSE, song_limit=SONG_LIMIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning GPT-2 Model Using Song Lyrics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining Dataset Class\n",
    "class Dset(torch.utils.data.Dataset):\n",
    "     \"\"\"A custom dataset\"\"\"\n",
    "     def __init__(self, data: list[list[int]]):\n",
    "         self.data = []\n",
    "         for d in data:\n",
    "             input_ids = torch.tensor(d, dtype=torch.int64)\n",
    "             attention_mask = torch.ones(len(d), dtype=torch.int64)\n",
    "             self.data.append({'input_ids': input_ids,\n",
    "                  'attention_mask': attention_mask, 'labels': input_ids})\n",
    " \n",
    "     def __len__(self):\n",
    "         return len(self.data)\n",
    " \n",
    "     def __getitem__(self, idx: int):\n",
    "         return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_tokenizer():\n",
    "    # get model\n",
    "    pipe = transformers.pipeline(task='text-generation', model='gpt2', device=DEVICE)\n",
    "    model = transformers.GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    # set model configurations\n",
    "    config = transformers.GPT2Config.from_pretrained('gpt2')\n",
    "    config.do_sample = True\n",
    "    config.max_length = MAX_SEQ_LEN\n",
    "\n",
    "    # get tokenizer\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "    # add padding token to tokenizer\n",
    "    tokenizer.add_special_tokens({'pad_token': \"[PAD]\"})\n",
    "\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model = transformers.GPT2LMHeadModel.from_pretrained('gpt2',\n",
    "                                                        config=model.config)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dset_train, dset_val):\n",
    "    \n",
    "    # set training arguments\n",
    "    training_args = transformers.TrainingArguments(\n",
    "     output_dir=\"gpt2-lyrics-model_save/training_args\",\n",
    "     learning_rate=1e-3,\n",
    "     per_device_train_batch_size=4, #TODO try changing to 20\n",
    "     per_device_eval_batch_size=4, #TODO try changing to 20\n",
    "     num_train_epochs=1,\n",
    "     evaluation_strategy='epoch',\n",
    "     save_strategy='no',\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dset_train,\n",
    "        eval_dataset=dset_val,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_texts(model, tokenizer, n_texts):\n",
    "    encoded_texts = []\n",
    "    texts = []\n",
    "    pad_token_id = 50257 # TODO generalize this\n",
    "\n",
    "    for _ in range(n_texts):\n",
    "\n",
    "        inputs = tokenizer(\" \", return_tensors=\"pt\")\n",
    "        encoded_output = model.generate(**inputs, pad_token_id=pad_token_id)\n",
    "        text_output = tokenizer.batch_decode(encoded_output)\n",
    "\n",
    "        encoded_texts.append(encoded_output)\n",
    "        texts.append(text_output[0])\n",
    "    \n",
    "    return encoded_texts, texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model and tokenizer\n",
    "model, tokenizer = get_model_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, valdation, and testing data \n",
    "train_data, val_data = train_test_split(song_lyrics, train_size=0.8)\n",
    "\n",
    "# encode data\n",
    "train_encodings = [tokenizer(text=x, return_tensors='pt', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in train_data]\n",
    "train_encodings = [enc['input_ids'].tolist()[0] for enc in train_encodings]\n",
    "\n",
    "val_encodings = [tokenizer(text=x, return_tensors='pt', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in val_data]\n",
    "val_encodings = [enc['input_ids'].tolist()[0] for enc in val_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and valdation datasets\n",
    "dset_train = Dset(train_encodings)\n",
    "dset_val = Dset(val_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \n",
      "100%|██████████| 3/3 [00:18<00:00,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.33721399307251, 'eval_runtime': 0.5971, 'eval_samples_per_second': 5.025, 'eval_steps_per_second': 1.675, 'epoch': 1.0}\n",
      "{'train_runtime': 18.0906, 'train_samples_per_second': 0.497, 'train_steps_per_second': 0.166, 'train_loss': 21.97089131673177, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fine tune the model\n",
    "model = train_model(model, tokenizer, dset_train, dset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 3 lyrics\n",
    "encoded_gen_texts, gen_texts = generate_texts(model, tokenizer, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity(model, tokenizer, test_text):\n",
    "    \n",
    "    encodings = tokenizer(\"\\n\\n\".join(test_text), return_tensors=\"pt\")\n",
    "\n",
    "    max_length = model.config.n_positions\n",
    "    stride = 512\n",
    "    seq_len = MAX_SEQ_LEN\n",
    "\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(DEVICE)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "            # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "            # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "            # to the left by 1.\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    # convert to scalar\n",
    "    ppl = ppl.numpy().tolist()\n",
    "\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9566.6787109375"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute perplexity of generated lyrics\n",
    "ppl = compute_perplexity(model, tokenizer, gen_texts)\n",
    "ppl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
