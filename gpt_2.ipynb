{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from gpt2_utils import Dset \n",
    "from gpt2_utils import get_model_tokenizer, train_model, generate_texts, load_model, compute_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "MAX_SEQ_LEN = 10\n",
    "DEVICE = 'cpu'\n",
    "VERBOSE = True\n",
    "\n",
    "GENRE = 'country'\n",
    "\n",
    "# Name of this trained model, will be used for filename when saving the model\n",
    "MODEL_INSTANCE_NAME = 'foo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in train, vallidation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned data\n",
    "if GENRE == 'country':\n",
    "    train_lines = pd.read_csv('data/country_train.csv', header=None).values.tolist()\n",
    "    val_lines = pd.read_csv('data/country_val.csv', header=None).values.tolist()\n",
    "    test_lines = pd.read_csv('data/country_test.csv', header=None).values.tolist()\n",
    "\n",
    "elif GENRE == 'metal':\n",
    "    train_lines = pd.read_csv('data/metal_train.csv', header=None).values.tolist()\n",
    "    val_lines = pd.read_csv('data/metal_val.csv', header=None).values.tolist()\n",
    "    test_lines = pd.read_csv('data/metal_test.csv', header=None).values.tolist()\n",
    "\n",
    "else:\n",
    "    raise ValueError('Incorrect genre given.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train lines :', len(train_lines))\n",
    "print('val lines : ', len(val_lines))\n",
    "print('test lines : ', len(test_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end = math.ceil(len(train_lines)/4)\n",
    "train_lines = train_lines[0:train_end]\n",
    "\n",
    "val_end = math.ceil(len(val_lines)/4)\n",
    "val_lines = val_lines[0:val_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model and tokenizer\n",
    "model, tokenizer = get_model_tokenizer(MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data\n",
    "train_encodings = [tokenizer(text=x, return_tensors='tf', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in train_lines]\n",
    "train_encodings = [enc['input_ids'].numpy().tolist()[0] for enc in train_encodings]\n",
    "\n",
    "val_encodings = [tokenizer(text=x, return_tensors='tf', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in val_lines]\n",
    "val_encodings = [enc['input_ids'].numpy().tolist()[0] for enc in val_encodings]\n",
    "\n",
    "test_encodings = [tokenizer(text=x, return_tensors='tf', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in test_lines]\n",
    "test_encodings = [enc['input_ids'].numpy().tolist()[0] for enc in test_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, valdation, and testing datasets\n",
    "dset_train = Dset(train_encodings)\n",
    "dset_val = Dset(val_encodings)\n",
    "dset_test = Dset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: only uncomment below if you want to fine tune a model. It make take a long time to run.\n",
    "# # fine tune the model\n",
    "# model = train_model(model, dset_train, dset_val, GENRE, MODEL_INSTANCE_NAME, batches=100, epochs=1, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lyrics\n",
    "gen_texts = generate_texts(model, tokenizer, 15)\n",
    "for text in gen_texts:\n",
    "    print(''.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Text from a Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"gpt2_trained_models/metal/100_lines_10_epoch\")\n",
    "gen_texts = generate_texts(loaded_model, tokenizer, 2, \"generated_txts/foo.txt\")\n",
    "for text in gen_texts:\n",
    "    print(''.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute perplexity of on test data\n",
    "test_lines_flt = np.array(test_lines).flatten().tolist()\n",
    "ppl = compute_perplexity('gpt2_trained_models/metal/100_lines_10_epoch', tokenizer, test_lines_flt, MAX_SEQ_LEN)\n",
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
