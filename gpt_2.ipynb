{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gpt2_utils import Dset \n",
    "from gpt2_utils import get_model_tokenizer, train_model, generate_texts, compute_perplexity, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "MAX_SEQ_LEN = 10\n",
    "DEVICE = 'cpu'\n",
    "VERBOSE = True\n",
    "\n",
    "GENRE = 'metal'\n",
    "\n",
    "# Name of this trained model, will be used for filename when saving the model\n",
    "MODEL_INSTANCE_NAME = 'all_songs_50_epoch_0.0001_lr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in train, vallidation, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in cleaned data\n",
    "if GENRE == 'country':\n",
    "    train_lines = pd.read_csv('country_train.csv', header=None).values.tolist()\n",
    "    val_lines = pd.read_csv('country_val.csv', header=None).values.tolist()\n",
    "    test_lines = pd.read_csv('country_test.csv', header=None).values.tolist()\n",
    "\n",
    "elif GENRE == 'metal':\n",
    "    train_lines = pd.read_csv('metal_train.csv', header=None).values.tolist()\n",
    "    val_lines = pd.read_csv('metal_val.csv', header=None).values.tolist()\n",
    "    test_lines = pd.read_csv('metal_test.csv', header=None).values.tolist()\n",
    "\n",
    "else:\n",
    "    raise ValueError('Incorrect genre given.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train lines :', len(train_lines))\n",
    "print('val lines : ', len(val_lines))\n",
    "print('test lines : ', len(test_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model and tokenizer\n",
    "model, tokenizer = get_model_tokenizer(MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = train_lines[0:100]\n",
    "val_lines = val_lines[0:100]\n",
    "test_lines = test_lines[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode data\n",
    "train_encodings = [tokenizer(text=x, return_tensors='pt', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in train_lines]\n",
    "train_encodings = [enc['input_ids'].tolist()[0] for enc in train_encodings]\n",
    "\n",
    "val_encodings = [tokenizer(text=x, return_tensors='pt', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in val_lines]\n",
    "val_encodings = [enc['input_ids'].tolist()[0] for enc in val_encodings]\n",
    "\n",
    "test_encodings = [tokenizer(text=x, return_tensors='pt', padding='max_length', max_length=MAX_SEQ_LEN, truncation=True) for x in test_lines]\n",
    "test_encodings = [enc['input_ids'].tolist()[0] for enc in test_encodings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, valdation, and testing datasets\n",
    "dset_train = Dset(train_encodings)\n",
    "dset_val = Dset(val_encodings)\n",
    "dset_test = Dset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the model\n",
    "model = train_model(model, dset_train, dset_val, GENRE, MODEL_INSTANCE_NAME, batches=20, epochs=50, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lyrics\n",
    "gen_texts = generate_texts(model, tokenizer, 15)\n",
    "for text in gen_texts:\n",
    "    print(''.join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute perplexity of generated lyrics\n",
    "import numpy as np\n",
    "test_lines_flt = np.array(test_lines).flatten().tolist()\n",
    "ppl = compute_perplexity(model, tokenizer, test_lines_flt, MAX_SEQ_LEN, DEVICE)\n",
    "ppl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
